{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dipendra7/2015lab1/blob/master/OpenAIPong_DQN_edit_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4AS7njD7iL6",
        "outputId": "669e26e4-1104-4f2c-95b7-cdf060f731f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep  3 19:44:28 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0              42W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting ale-py~=0.7.5 (from gym[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (6.4.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (4.66.5)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2024.7.4)\n",
            "Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446662 sha256=8c9a5eb6943a193d43e0dc35250410493cb50b461c137e093468fbbd347f0841\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: ale-py, AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip install \"gym[atari, accept-rom-license]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-D98CddQuwKG"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import cv2\n",
        "\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8rGMlN2uzgk",
        "outputId": "7e104a70-ede5-42e0-98ef-beea7d4331ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "ENVIRONMENT = \"PongDeterministic-v4\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_MODELS = True  # Save models to file so you can test later\n",
        "MODEL_PATH = \"./pong-cnn-\"  # Models path for saving or loading\n",
        "SAVE_MODEL_INTERVAL = 100  # Save models at every X epoch\n",
        "TRAIN_MODEL = True  # Train model while playing (Make it False when testing a model)\n",
        "\n",
        "LOAD_MODEL_FROM_FILE = False  # Load model from file\n",
        "LOAD_FILE_EPISODE = 0  # Load Xth episode from file\n",
        "\n",
        "BATCH_SIZE = 128  # Minibatch size that select randomly from mem for train nets\n",
        "MAX_EPISODE = 10000  # Max episode\n",
        "MAX_STEP = 5000  # Max step size for one episode\n",
        "\n",
        "MAX_MEMORY_LEN = 50000  # Max memory len\n",
        "MIN_MEMORY_LEN = 40000  # Min memory len before start train\n",
        "\n",
        "GAMMA = 0.97  # Discount rate\n",
        "ALPHA = 0.00001  # Learning rate\n",
        "EPSILON_DECAY = 0.99  # Epsilon decay rate by step\n",
        "\n",
        "RENDER_GAME_WINDOW = False  # Opens a new window to render the game (Won't work on colab default)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OdCBu_7LoAE4"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import norse.torch as snn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# # Create SNN Arhitecture that will inherit layers from nn.Module\n",
        "# class SNN(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "#         super(SNN, self).__init__()\n",
        "\n",
        "#         # Convolutional layer\n",
        "#         self.fc0 = nn.Conv2d(3, 1, 5)\n",
        "\n",
        "#         # First fully connected layer\n",
        "#         self.fc2 = nn.Linear(32136, 256)  # Adjusted based on input dim\n",
        "\n",
        "#         # Output layer\n",
        "#         self.fc3 = nn.Linear(256, output_dim)\n",
        "\n",
        "#         # Dropout\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#         # LIF cells to replace ReLU activations\n",
        "#         self.lif0 = snn.LIFCell()  # For the first convolutional layer\n",
        "#         self.lif1 = snn.LIFCell()  # For the first fully connected layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Change input shape to match the convolutional layer expectations\n",
        "#         x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "#         # Convolutional layer + LIF\n",
        "#         x = self.fc0(x)\n",
        "#         lif0_state = None\n",
        "#         x, lif0_state = self.lif0(x, lif0_state)\n",
        "\n",
        "#         # Flatten the output for the fully connected layer\n",
        "#         x = torch.flatten(x, start_dim=1)  # Flatten along the batch dimension\n",
        "\n",
        "#         # First fully connected layer + LIF\n",
        "#         x = self.fc2(x)\n",
        "#         lif1_state = None\n",
        "#         x, lif1_state = self.lif1(x, lif1_state)\n",
        "\n",
        "#         # Apply dropout\n",
        "#         x = self.dropout(x)\n",
        "\n",
        "#         # Output layer (no activation for final output)\n",
        "#         x = self.fc3(x)\n",
        "\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HxF5-bzUu1q-"
      },
      "outputs": [],
      "source": [
        "# class DuelCNN(nn.Module):\n",
        "#     \"\"\"\n",
        "#     CNN with Duel Algo. https://arxiv.org/abs/1511.06581\n",
        "#     \"\"\"\n",
        "#     def __init__(self, h, w, output_size):\n",
        "#         super(DuelCNN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels=4,  out_channels=32, kernel_size=8, stride=4)\n",
        "#         self.bn1 = nn.BatchNorm2d(32)\n",
        "#         convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "#         self.bn2 = nn.BatchNorm2d(64)\n",
        "#         convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "#         self.bn3 = nn.BatchNorm2d(64)\n",
        "#         convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "\n",
        "#         linear_input_size = convw * convh * 64  # Last conv layer's out sizes\n",
        "\n",
        "#         # Action layer\n",
        "#         self.Alinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "#         self.Alrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "#         self.Alinear2 = nn.Linear(in_features=128, out_features=output_size)\n",
        "\n",
        "#         # State Value layer\n",
        "#         self.Vlinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "#         self.Vlrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "#         self.Vlinear2 = nn.Linear(in_features=128, out_features=1)  # Only 1 node\n",
        "\n",
        "#     def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "#         \"\"\"\n",
        "#         Calcs conv layers output image sizes\n",
        "#         \"\"\"\n",
        "#         next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "#         next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "#         return next_w, next_h\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.bn1(self.conv1(x)))\n",
        "#         x = F.relu(self.bn2(self.conv2(x)))\n",
        "#         x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "#         x = x.view(x.size(0), -1)  # Flatten every batch\n",
        "\n",
        "#         Ax = self.Alrelu(self.Alinear1(x))\n",
        "#         Ax = self.Alinear2(Ax)  # No activation on last layer\n",
        "\n",
        "#         Vx = self.Vlrelu(self.Vlinear1(x))\n",
        "#         Vx = self.Vlinear2(Vx)  # No activation on last layer\n",
        "\n",
        "#         q = Vx + (Ax - Ax.mean())\n",
        "\n",
        "#         return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM-MLel69fIx",
        "outputId": "a61718ae-5707-486e-f105-6ac434f5c366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting norse\n",
            "  Downloading norse-1.1.0.tar.gz (1.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from norse) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from norse) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from norse) (0.19.0+cu121)\n",
            "Collecting nir (from norse)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nirtorch (from norse)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->norse) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.15.0->norse) (9.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->norse) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->norse) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->norse) (1.3.0)\n",
            "Downloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: norse\n",
            "  Building wheel for norse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for norse: filename=norse-1.1.0-py3-none-any.whl size=1539018 sha256=84400d263db4de4adf567c105c71d7bd6a69390de55b158150ea804e667ee411\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/fc/0d/4cbb14992b7e5bb35482df57e887a2ab55cad9ea890501cf61\n",
            "Successfully built norse\n",
            "Installing collected packages: nir, nirtorch, norse\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 norse-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install norse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyGgOeYhoeSJ",
        "outputId": "9cad9000-c67c-49ee-856b-ea121fd4bc24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_cxx_pytree.py:242: UserWarning: PyTree type <class 'norse.torch.utils.pytree.LIFParameters'> is a subclass of `collections.namedtuple`, which is already registered in the global namespace. Override it with custom flatten/unflatten functions in namespace 'torch'.\n",
            "  optree.register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_cxx_pytree.py:242: UserWarning: PyTree type <class 'norse.torch.utils.pytree.LIFBoxParameters'> is a subclass of `collections.namedtuple`, which is already registered in the global namespace. Override it with custom flatten/unflatten functions in namespace 'torch'.\n",
            "  optree.register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "import torch.nn as nn\n",
        "import norse.torch as snn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, h, w, output_size, dropout=0.5):\n",
        "        super(SNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers with appropriate dimensions\n",
        "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "\n",
        "        linear_input_size = convw * convh * 64  # Adjust input size for linear layers\n",
        "\n",
        "        # Fully connected layers with LIF cells\n",
        "        self.fc1 = nn.Linear(linear_input_size, 128)\n",
        "        self.lif1 = snn.LIFCell()\n",
        "\n",
        "        self.fc2 = nn.Linear(128, output_size)\n",
        "        self.lif2 = snn.LIFCell()\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "        \"\"\"\n",
        "        Calculate convolutional layers output image sizes\n",
        "        \"\"\"\n",
        "        next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "        next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "        return next_w, next_h\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)  # Flatten along the batch dimension\n",
        "\n",
        "        # Fully connected layers with LIF activation\n",
        "        x = self.fc1(x)\n",
        "        lif1_state = None\n",
        "        x, lif1_state = self.lif1(x, lif1_state)\n",
        "\n",
        "        # Apply dropout\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        lif2_state = None\n",
        "        x, lif2_state = self.lif2(x, lif2_state)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9g7gdSNQjiW",
        "outputId": "c61dcc13-574b-4807-c8c8-2f8f461af6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import norse.torch as snn\n",
        "\n",
        "# class SNN(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Enhanced SNN with Dueling Architecture, simplified for better performance.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, h, w, output_size):\n",
        "#         super(SNN, self).__init__()\n",
        "\n",
        "#         # Convolutional layers with LIF cells\n",
        "#         self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4)\n",
        "#         self.norm1 = nn.GroupNorm(8, 32)  # GroupNorm for stability with small batch sizes\n",
        "#         self.lif1 = snn.LIFCell()  # LIF after first conv layer\n",
        "\n",
        "#         convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "#         self.norm2 = nn.GroupNorm(16, 64)  # GroupNorm for stability with small batch sizes\n",
        "#         self.lif2 = snn.LIFCell()  # LIF after second conv layer\n",
        "\n",
        "#         convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "#         self.norm3 = nn.GroupNorm(16, 64)  # GroupNorm for stability with small batch sizes\n",
        "#         self.lif3 = snn.LIFCell()  # LIF after third conv layer\n",
        "\n",
        "#         convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "#         linear_input_size = convw * convh * 64  # Calculate the flattened size for fully connected layers\n",
        "\n",
        "#         # Dropout for regularization\n",
        "#         self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "#         # Action stream\n",
        "#         self.Alinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "#         self.Alif = snn.LIFCell()  # LIF after first linear layer in action stream\n",
        "#         self.Arelu = nn.ReLU()  # ReLU to help with gradient flow\n",
        "#         self.Alinear2 = nn.Linear(in_features=128, out_features=output_size)\n",
        "\n",
        "#         # State Value stream\n",
        "#         self.Vlinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "#         self.Vlif = snn.LIFCell()  # LIF after first linear layer in value stream\n",
        "#         self.Vrelu = nn.ReLU()  # ReLU to help with gradient flow\n",
        "#         self.Vlinear2 = nn.Linear(in_features=128, out_features=1)  # Only 1 node for state value\n",
        "\n",
        "#     def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "#         \"\"\"\n",
        "#         Calculates convolutional layers' output image sizes\n",
        "#         \"\"\"\n",
        "#         next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "#         next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "#         return next_w, next_h\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF states\n",
        "#         lif1_state = None\n",
        "#         lif2_state = None\n",
        "#         lif3_state = None\n",
        "\n",
        "#         # Conv Layer 1 + LIF + Norm\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.norm1(x)\n",
        "#         x, lif1_state = self.lif1(x, lif1_state)\n",
        "\n",
        "#         # Conv Layer 2 + LIF + Norm\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.norm2(x)\n",
        "#         x, lif2_state = self.lif2(x, lif2_state)\n",
        "\n",
        "#         # Conv Layer 3 + LIF + Norm\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.norm3(x)\n",
        "#         x, lif3_state = self.lif3(x, lif3_state)\n",
        "\n",
        "#         # Flatten the output for the fully connected layers\n",
        "#         x = x.view(x.size(0), -1)\n",
        "\n",
        "#         # Apply dropout for regularization\n",
        "#         x = self.dropout(x)\n",
        "\n",
        "#         # Action stream + LIF + ReLU\n",
        "#         Ax = self.Alinear1(x)\n",
        "#         Ax, _ = self.Alif(Ax, None)\n",
        "#         Ax = self.Arelu(Ax)\n",
        "#         Ax = self.Alinear2(Ax)\n",
        "\n",
        "#         # State Value stream + LIF + ReLU\n",
        "#         Vx = self.Vlinear1(x)\n",
        "#         Vx, _ = self.Vlif(Vx, None)\n",
        "#         Vx = self.Vrelu(Vx)\n",
        "#         Vx = self.Vlinear2(Vx)\n",
        "\n",
        "#         # Combine the streams into the Q-value output\n",
        "#         q = Vx + (Ax - Ax.mean(dim=1, keepdim=True))\n",
        "\n",
        "#         return q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "plT51MPbu5U5"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, environment):\n",
        "        \"\"\"\n",
        "        Hyperparameters definition for Agent\n",
        "        \"\"\"\n",
        "        # State size for breakout env. SS images (210, 160, 3). Used as input size in network\n",
        "        self.state_size_h = environment.observation_space.shape[0]\n",
        "        self.state_size_w = environment.observation_space.shape[1]\n",
        "        self.state_size_c = environment.observation_space.shape[2]\n",
        "\n",
        "        # Activation size for breakout env. Used as output size in network\n",
        "        self.action_size = environment.action_space.n\n",
        "\n",
        "        # Image pre process params\n",
        "        self.target_h = 80  # Height after process\n",
        "        self.target_w = 64  # Widht after process\n",
        "\n",
        "        self.crop_dim = [20, self.state_size_h, 0, self.state_size_w]  # Cut 20 px from top to get rid of the score table\n",
        "\n",
        "        # Trust rate to our experiences\n",
        "        self.gamma = GAMMA  # Discount coef for future predictions\n",
        "        self.alpha = ALPHA  # Learning Rate\n",
        "\n",
        "        # After many experinces epsilon will be 0.05\n",
        "        # So we will do less Explore more Exploit\n",
        "        self.epsilon = 1  # Explore or Exploit\n",
        "        self.epsilon_decay = EPSILON_DECAY  # Adaptive Epsilon Decay Rate\n",
        "        self.epsilon_minimum = 0.05  # Minimum for Explore\n",
        "\n",
        "        # Deque holds replay mem.\n",
        "        self.memory = deque(maxlen=MAX_MEMORY_LEN)\n",
        "\n",
        "        # Create two model for DDQN algorithm\n",
        "        self.online_model = SNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model = SNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model.load_state_dict(self.online_model.state_dict())\n",
        "        self.target_model.eval()\n",
        "\n",
        "        # Adam used as optimizer\n",
        "        self.optimizer = optim.Adam(self.online_model.parameters(), lr=self.alpha)\n",
        "\n",
        "    def preProcess(self, image):\n",
        "        \"\"\"\n",
        "        Process image crop resize, grayscale and normalize the images\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # To grayscale\n",
        "        frame = frame[self.crop_dim[0]:self.crop_dim[1], self.crop_dim[2]:self.crop_dim[3]]  # Cut 20 px from top\n",
        "        frame = cv2.resize(frame, (self.target_w, self.target_h))  # Resize\n",
        "        frame = frame.reshape(self.target_w, self.target_h) / 255  # Normalize\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Get state and do action\n",
        "        Two option can be selectedd if explore select random action\n",
        "        if exploit ask nnet for action\n",
        "        \"\"\"\n",
        "\n",
        "        act_protocol = 'Explore' if random.uniform(0, 1) <= self.epsilon else 'Exploit'\n",
        "\n",
        "        if act_protocol == 'Explore':\n",
        "            action = random.randrange(self.action_size)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "                q_values = self.online_model.forward(state)  # (1, action_size)\n",
        "                action = torch.argmax(q_values).item()  # Returns the indices of the maximum value of all elements\n",
        "\n",
        "        return action\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train neural nets with replay memory\n",
        "        returns loss and max_q val predicted from online_net\n",
        "        \"\"\"\n",
        "        if len(agent.memory) < MIN_MEMORY_LEN:\n",
        "            loss, max_q = [0, 0]\n",
        "            return loss, max_q\n",
        "        # We get out minibatch and turn it to numpy array\n",
        "        state, action, reward, next_state, done = zip(*random.sample(self.memory, BATCH_SIZE))\n",
        "\n",
        "        # Concat batches in one array\n",
        "        # (np.arr, np.arr) ==> np.BIGarr\n",
        "        state = np.concatenate(state)\n",
        "        next_state = np.concatenate(next_state)\n",
        "\n",
        "        # Convert them to tensors\n",
        "        state = torch.tensor(state, dtype=torch.float, device=DEVICE)\n",
        "        next_state = torch.tensor(next_state, dtype=torch.float, device=DEVICE)\n",
        "        action = torch.tensor(action, dtype=torch.long, device=DEVICE)\n",
        "        reward = torch.tensor(reward, dtype=torch.float, device=DEVICE)\n",
        "        done = torch.tensor(done, dtype=torch.float, device=DEVICE)\n",
        "\n",
        "        # Make predictions\n",
        "        state_q_values = self.online_model(state)\n",
        "        next_states_q_values = self.online_model(next_state)\n",
        "        next_states_target_q_values = self.target_model(next_state)\n",
        "\n",
        "        # Find selected action's q_value\n",
        "        selected_q_value = state_q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "        # Get indice of the max value of next_states_q_values\n",
        "        # Use that indice to get a q_value from next_states_target_q_values\n",
        "        # We use greedy for policy So it called off-policy\n",
        "        next_states_target_q_value = next_states_target_q_values.gather(1, next_states_q_values.max(1)[1].unsqueeze(1)).squeeze(1)\n",
        "        # Use Bellman function to find expected q value\n",
        "        expected_q_value = reward + self.gamma * next_states_target_q_value * (1 - done)\n",
        "\n",
        "        # Calc loss with expected_q_value and q_value\n",
        "        loss = (selected_q_value - expected_q_value.detach()).pow(2).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, torch.max(state_q_values).item()\n",
        "\n",
        "    def storeResults(self, state, action, reward, nextState, done):\n",
        "        \"\"\"\n",
        "        Store every result to memory\n",
        "        \"\"\"\n",
        "        self.memory.append([state[None, :], action, reward, nextState[None, :], done])\n",
        "\n",
        "    def adaptiveEpsilon(self):\n",
        "        \"\"\"\n",
        "        Adaptive Epsilon means every step\n",
        "        we decrease the epsilon so we do less Explore\n",
        "        \"\"\"\n",
        "        if self.epsilon > self.epsilon_minimum:\n",
        "            self.epsilon *= self.epsilon_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve4vYDe3bozg",
        "outputId": "4546610e-cb42-4243-d26f-09fdef90aa28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Time:19:44:59 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.000 Epsilon:1.00 Duration:0.78 Step:920 CStep:922\n",
            "Episode:2 Time:19:45:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.99 Duration:1.76 Step:945 CStep:1868\n",
            "Episode:3 Time:19:45:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.98 Duration:0.65 Step:764 CStep:2633\n",
            "Episode:4 Time:19:45:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.750 Avg_Max_Q:0.000 Epsilon:0.97 Duration:0.90 Step:963 CStep:3597\n",
            "Episode:5 Time:19:45:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.96 Duration:0.76 Step:792 CStep:4390\n",
            "Episode:6 Time:19:45:04 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.95 Duration:0.90 Step:997 CStep:5388\n",
            "Episode:7 Time:19:45:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.571 Avg_Max_Q:0.000 Epsilon:0.94 Duration:0.77 Step:856 CStep:6245\n",
            "Episode:8 Time:19:45:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.625 Avg_Max_Q:0.000 Epsilon:0.93 Duration:0.79 Step:868 CStep:7114\n",
            "Episode:9 Time:19:45:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.93 Duration:0.83 Step:880 CStep:7995\n",
            "Episode:10 Time:19:45:07 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.600 Avg_Max_Q:0.000 Epsilon:0.91 Duration:1.00 Step:1041 CStep:9037\n",
            "Episode:11 Time:19:45:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.636 Avg_Max_Q:0.000 Epsilon:0.91 Duration:0.80 Step:812 CStep:9850\n",
            "Episode:12 Time:19:45:09 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.583 Avg_Max_Q:0.000 Epsilon:0.90 Duration:0.94 Step:962 CStep:10813\n",
            "Episode:13 Time:19:45:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.615 Avg_Max_Q:0.000 Epsilon:0.90 Duration:0.83 Step:831 CStep:11645\n",
            "Episode:14 Time:19:45:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.643 Avg_Max_Q:0.000 Epsilon:0.89 Duration:0.79 Step:783 CStep:12429\n",
            "Episode:15 Time:19:45:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.80 Step:793 CStep:13223\n",
            "Episode:16 Time:19:45:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.688 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.80 Step:764 CStep:13988\n",
            "Episode:17 Time:19:45:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.706 Avg_Max_Q:0.000 Epsilon:0.87 Duration:0.93 Step:912 CStep:14901\n",
            "Episode:18 Time:19:45:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.722 Avg_Max_Q:0.000 Epsilon:0.86 Duration:1.16 Step:824 CStep:15726\n",
            "Episode:19 Time:19:45:15 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.737 Avg_Max_Q:0.000 Epsilon:0.85 Duration:0.82 Step:764 CStep:16491\n",
            "Episode:20 Time:19:45:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.84 Duration:1.13 Step:1043 CStep:17535\n",
            "Episode:21 Time:19:45:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.88 Step:792 CStep:18328\n",
            "Episode:22 Time:19:45:18 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.682 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.97 Step:870 CStep:19199\n",
            "Episode:23 Time:19:45:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.696 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.89 Step:792 CStep:19992\n",
            "Episode:24 Time:19:45:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.708 Avg_Max_Q:0.000 Epsilon:0.82 Duration:0.99 Step:858 CStep:20851\n",
            "Episode:25 Time:19:45:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.81 Duration:0.96 Step:826 CStep:21678\n",
            "Episode:26 Time:19:45:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.731 Avg_Max_Q:0.000 Epsilon:0.80 Duration:1.12 Step:946 CStep:22625\n",
            "Episode:27 Time:19:45:23 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.79 Duration:1.15 Step:999 CStep:23625\n",
            "Episode:28 Time:19:45:24 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.679 Avg_Max_Q:0.000 Epsilon:0.79 Duration:0.95 Step:810 CStep:24436\n",
            "Episode:29 Time:19:45:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.690 Avg_Max_Q:0.000 Epsilon:0.78 Duration:1.17 Step:962 CStep:25399\n",
            "Episode:30 Time:19:45:27 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.77 Duration:1.18 Step:979 CStep:26379\n",
            "Episode:31 Time:19:45:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.677 Avg_Max_Q:0.000 Epsilon:0.76 Duration:1.18 Step:941 CStep:27321\n",
            "Episode:32 Time:19:45:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.688 Avg_Max_Q:0.000 Epsilon:0.75 Duration:1.03 Step:792 CStep:28114\n",
            "Episode:33 Time:19:45:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.697 Avg_Max_Q:0.000 Epsilon:0.75 Duration:1.17 Step:913 CStep:29028\n",
            "Episode:34 Time:19:45:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.706 Avg_Max_Q:0.000 Epsilon:0.75 Duration:1.11 Step:854 CStep:29883\n",
            "Episode:35 Time:19:45:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.000 Epsilon:0.74 Duration:1.02 Step:764 CStep:30648\n",
            "Episode:36 Time:19:45:33 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.722 Avg_Max_Q:0.000 Epsilon:0.73 Duration:1.04 Step:764 CStep:31413\n",
            "Episode:37 Time:19:45:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.72 Duration:1.15 Step:880 CStep:32294\n",
            "Episode:38 Time:19:45:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.737 Avg_Max_Q:0.000 Epsilon:0.72 Duration:1.14 Step:854 CStep:33149\n",
            "Episode:39 Time:19:45:37 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.718 Avg_Max_Q:0.000 Epsilon:0.71 Duration:1.39 Step:1003 CStep:34153\n",
            "Episode:40 Time:19:45:38 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.70 Duration:1.44 Step:1046 CStep:35200\n",
            "Episode:41 Time:19:45:39 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.683 Avg_Max_Q:0.000 Epsilon:0.70 Duration:1.17 Step:872 CStep:36073\n",
            "Episode:42 Time:19:45:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.690 Avg_Max_Q:0.000 Epsilon:0.69 Duration:1.32 Step:944 CStep:37018\n",
            "Episode:43 Time:19:45:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.698 Avg_Max_Q:0.000 Epsilon:0.69 Duration:1.10 Step:792 CStep:37811\n",
            "Episode:44 Time:19:45:43 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.682 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.42 Step:1041 CStep:38853\n",
            "Episode:45 Time:19:45:45 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.34 Step:923 CStep:39777\n",
            "Episode:46 Time:19:46:09 Reward:-21.00 Loss:16.91 Last_100_Avg_Rew:-20.674 Avg_Max_Q:0.000 Epsilon:0.67 Duration:24.29 Step:945 CStep:40723\n",
            "Episode:47 Time:19:46:34 Reward:-21.00 Loss:18.54 Last_100_Avg_Rew:-20.681 Avg_Max_Q:0.000 Epsilon:0.66 Duration:24.73 Step:764 CStep:41488\n",
            "Episode:48 Time:19:46:59 Reward:-21.00 Loss:19.00 Last_100_Avg_Rew:-20.688 Avg_Max_Q:0.000 Epsilon:0.66 Duration:25.44 Step:793 CStep:42282\n",
            "Episode:49 Time:19:47:26 Reward:-21.00 Loss:20.48 Last_100_Avg_Rew:-20.694 Avg_Max_Q:0.000 Epsilon:0.65 Duration:27.25 Step:854 CStep:43137\n",
            "Episode:50 Time:19:47:55 Reward:-21.00 Loss:21.45 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.64 Duration:28.33 Step:884 CStep:44022\n",
            "Episode:51 Time:19:48:22 Reward:-20.00 Loss:20.73 Last_100_Avg_Rew:-20.686 Avg_Max_Q:0.000 Epsilon:0.64 Duration:26.99 Step:842 CStep:44865\n",
            "Episode:52 Time:19:48:53 Reward:-21.00 Loss:23.47 Last_100_Avg_Rew:-20.692 Avg_Max_Q:0.000 Epsilon:0.64 Duration:30.97 Step:964 CStep:45830\n",
            "Episode:53 Time:19:49:21 Reward:-21.00 Loss:20.52 Last_100_Avg_Rew:-20.698 Avg_Max_Q:0.000 Epsilon:0.63 Duration:28.25 Step:884 CStep:46715\n",
            "Episode:54 Time:19:49:45 Reward:-21.00 Loss:18.33 Last_100_Avg_Rew:-20.704 Avg_Max_Q:0.000 Epsilon:0.62 Duration:24.37 Step:764 CStep:47480\n",
            "Episode:55 Time:19:50:14 Reward:-21.00 Loss:21.16 Last_100_Avg_Rew:-20.709 Avg_Max_Q:0.000 Epsilon:0.62 Duration:28.54 Step:884 CStep:48365\n",
            "Episode:56 Time:19:50:41 Reward:-20.00 Loss:20.57 Last_100_Avg_Rew:-20.696 Avg_Max_Q:0.000 Epsilon:0.61 Duration:27.00 Step:842 CStep:49208\n",
            "Episode:57 Time:19:51:15 Reward:-21.00 Loss:24.40 Last_100_Avg_Rew:-20.702 Avg_Max_Q:0.000 Epsilon:0.61 Duration:33.86 Step:1003 CStep:50212\n",
            "Episode:58 Time:19:51:35 Reward:-21.00 Loss:18.53 Last_100_Avg_Rew:-20.707 Avg_Max_Q:0.000 Epsilon:0.61 Duration:20.02 Step:764 CStep:50977\n",
            "Episode:59 Time:19:52:00 Reward:-21.00 Loss:23.77 Last_100_Avg_Rew:-20.712 Avg_Max_Q:0.000 Epsilon:0.60 Duration:25.45 Step:972 CStep:51950\n",
            "Episode:60 Time:19:52:26 Reward:-21.00 Loss:23.36 Last_100_Avg_Rew:-20.717 Avg_Max_Q:0.000 Epsilon:0.59 Duration:25.40 Step:968 CStep:52919\n",
            "Episode:61 Time:19:52:52 Reward:-20.00 Loss:23.91 Last_100_Avg_Rew:-20.705 Avg_Max_Q:0.000 Epsilon:0.59 Duration:26.05 Step:990 CStep:53910\n",
            "Episode:62 Time:19:53:13 Reward:-21.00 Loss:18.84 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.58 Duration:21.19 Step:812 CStep:54723\n",
            "Episode:63 Time:19:53:39 Reward:-21.00 Loss:24.22 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.000 Epsilon:0.58 Duration:26.14 Step:1004 CStep:55728\n",
            "Episode:64 Time:19:54:07 Reward:-21.00 Loss:26.24 Last_100_Avg_Rew:-20.719 Avg_Max_Q:0.000 Epsilon:0.57 Duration:27.90 Step:1064 CStep:56793\n",
            "Episode:65 Time:19:54:31 Reward:-21.00 Loss:21.81 Last_100_Avg_Rew:-20.723 Avg_Max_Q:0.000 Epsilon:0.56 Duration:24.46 Step:932 CStep:57726\n",
            "Episode:66 Time:19:54:51 Reward:-21.00 Loss:18.52 Last_100_Avg_Rew:-20.727 Avg_Max_Q:0.000 Epsilon:0.56 Duration:20.01 Step:764 CStep:58491\n",
            "Episode:67 Time:19:55:19 Reward:-21.00 Loss:24.70 Last_100_Avg_Rew:-20.731 Avg_Max_Q:0.000 Epsilon:0.55 Duration:27.29 Step:1031 CStep:59523\n",
            "Episode:68 Time:19:55:42 Reward:-20.00 Loss:21.70 Last_100_Avg_Rew:-20.721 Avg_Max_Q:0.000 Epsilon:0.55 Duration:23.69 Step:902 CStep:60426\n",
            "Episode:69 Time:19:56:03 Reward:-21.00 Loss:18.19 Last_100_Avg_Rew:-20.725 Avg_Max_Q:0.000 Epsilon:0.54 Duration:20.93 Step:793 CStep:61220\n",
            "Episode:70 Time:19:56:25 Reward:-21.00 Loss:20.73 Last_100_Avg_Rew:-20.729 Avg_Max_Q:0.000 Epsilon:0.54 Duration:22.01 Step:824 CStep:62045\n",
            "Episode:71 Time:19:56:51 Reward:-21.00 Loss:23.76 Last_100_Avg_Rew:-20.732 Avg_Max_Q:0.000 Epsilon:0.53 Duration:26.13 Step:974 CStep:63020\n",
            "Episode:72 Time:19:57:14 Reward:-21.00 Loss:19.34 Last_100_Avg_Rew:-20.736 Avg_Max_Q:0.000 Epsilon:0.53 Duration:22.66 Step:852 CStep:63873\n",
            "Episode:73 Time:19:57:37 Reward:-20.00 Loss:20.45 Last_100_Avg_Rew:-20.726 Avg_Max_Q:0.000 Epsilon:0.53 Duration:22.53 Step:842 CStep:64716\n",
            "Episode:74 Time:19:57:57 Reward:-21.00 Loss:18.48 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.52 Duration:20.35 Step:764 CStep:65481\n",
            "Episode:75 Time:19:58:19 Reward:-21.00 Loss:20.34 Last_100_Avg_Rew:-20.733 Avg_Max_Q:0.000 Epsilon:0.52 Duration:22.18 Step:826 CStep:66308\n",
            "Episode:76 Time:19:58:42 Reward:-20.00 Loss:21.49 Last_100_Avg_Rew:-20.724 Avg_Max_Q:0.000 Epsilon:0.51 Duration:23.05 Step:878 CStep:67187\n",
            "Episode:77 Time:19:59:02 Reward:-21.00 Loss:18.76 Last_100_Avg_Rew:-20.727 Avg_Max_Q:0.000 Epsilon:0.51 Duration:19.97 Step:764 CStep:67952\n",
            "Episode:78 Time:19:59:22 Reward:-21.00 Loss:17.75 Last_100_Avg_Rew:-20.731 Avg_Max_Q:0.000 Epsilon:0.50 Duration:20.13 Step:764 CStep:68717\n",
            "Episode:79 Time:19:59:49 Reward:-21.00 Loss:24.94 Last_100_Avg_Rew:-20.734 Avg_Max_Q:0.000 Epsilon:0.50 Duration:26.90 Step:1032 CStep:69750\n",
            "Episode:80 Time:20:00:16 Reward:-20.00 Loss:25.77 Last_100_Avg_Rew:-20.725 Avg_Max_Q:0.000 Epsilon:0.49 Duration:27.33 Step:1040 CStep:70791\n",
            "Episode:81 Time:20:00:38 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.728 Avg_Max_Q:0.000 Epsilon:0.49 Duration:21.96 Step:824 CStep:71616\n",
            "Episode:82 Time:20:01:09 Reward:-21.00 Loss:27.70 Last_100_Avg_Rew:-20.732 Avg_Max_Q:0.000 Epsilon:0.48 Duration:30.54 Step:1151 CStep:72768\n",
            "Episode:83 Time:20:01:35 Reward:-19.00 Loss:22.85 Last_100_Avg_Rew:-20.711 Avg_Max_Q:0.000 Epsilon:0.48 Duration:25.74 Step:965 CStep:73734\n",
            "Episode:84 Time:20:02:00 Reward:-21.00 Loss:22.41 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.000 Epsilon:0.48 Duration:25.22 Step:946 CStep:74681\n",
            "Episode:85 Time:20:02:20 Reward:-21.00 Loss:17.67 Last_100_Avg_Rew:-20.718 Avg_Max_Q:0.000 Epsilon:0.47 Duration:20.29 Step:764 CStep:75446\n",
            "Episode:86 Time:20:02:42 Reward:-21.00 Loss:20.00 Last_100_Avg_Rew:-20.721 Avg_Max_Q:0.000 Epsilon:0.47 Duration:21.96 Step:824 CStep:76271\n",
            "Episode:87 Time:20:03:05 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.724 Avg_Max_Q:0.000 Epsilon:0.46 Duration:22.48 Step:824 CStep:77096\n",
            "Episode:88 Time:20:03:29 Reward:-21.00 Loss:21.39 Last_100_Avg_Rew:-20.727 Avg_Max_Q:0.000 Epsilon:0.46 Duration:24.81 Step:914 CStep:78011\n",
            "Episode:89 Time:20:03:50 Reward:-21.00 Loss:19.53 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.46 Duration:20.76 Step:792 CStep:78804\n",
            "Episode:90 Time:20:04:15 Reward:-21.00 Loss:21.93 Last_100_Avg_Rew:-20.733 Avg_Max_Q:0.000 Epsilon:0.45 Duration:24.66 Step:944 CStep:79749\n",
            "Episode:91 Time:20:04:36 Reward:-21.00 Loss:18.97 Last_100_Avg_Rew:-20.736 Avg_Max_Q:0.000 Epsilon:0.45 Duration:20.75 Step:792 CStep:80542\n",
            "Episode:92 Time:20:05:03 Reward:-18.00 Loss:24.24 Last_100_Avg_Rew:-20.707 Avg_Max_Q:0.000 Epsilon:0.44 Duration:27.26 Step:1032 CStep:81575\n",
            "Episode:93 Time:20:05:23 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.44 Duration:20.36 Step:764 CStep:82340\n",
            "Episode:94 Time:20:05:44 Reward:-21.00 Loss:17.38 Last_100_Avg_Rew:-20.713 Avg_Max_Q:0.000 Epsilon:0.43 Duration:20.46 Step:764 CStep:83105\n",
            "Episode:95 Time:20:06:10 Reward:-19.00 Loss:24.59 Last_100_Avg_Rew:-20.695 Avg_Max_Q:0.000 Epsilon:0.43 Duration:26.75 Step:1014 CStep:84120\n",
            "Episode:96 Time:20:06:32 Reward:-21.00 Loss:19.95 Last_100_Avg_Rew:-20.698 Avg_Max_Q:0.000 Epsilon:0.43 Duration:21.54 Step:824 CStep:84945\n",
            "Episode:97 Time:20:06:54 Reward:-21.00 Loss:19.95 Last_100_Avg_Rew:-20.701 Avg_Max_Q:0.000 Epsilon:0.43 Duration:21.56 Step:824 CStep:85770\n",
            "Episode:98 Time:20:07:18 Reward:-21.00 Loss:21.57 Last_100_Avg_Rew:-20.704 Avg_Max_Q:0.000 Epsilon:0.42 Duration:23.95 Step:913 CStep:86684\n",
            "Episode:99 Time:20:07:39 Reward:-21.00 Loss:19.55 Last_100_Avg_Rew:-20.707 Avg_Max_Q:0.000 Epsilon:0.42 Duration:21.63 Step:826 CStep:87511\n",
            "Episode:100 Time:20:08:05 Reward:-21.00 Loss:23.36 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.41 Duration:25.78 Step:975 CStep:88487\n",
            "Episode:101 Time:20:08:30 Reward:-21.00 Loss:21.51 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.41 Duration:25.08 Step:944 CStep:89432\n",
            "Episode:102 Time:20:08:51 Reward:-21.00 Loss:18.95 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.40 Duration:20.95 Step:792 CStep:90225\n",
            "Episode:103 Time:20:09:14 Reward:-21.00 Loss:21.16 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.40 Duration:23.38 Step:884 CStep:91110\n",
            "Episode:104 Time:20:09:35 Reward:-21.00 Loss:17.92 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.40 Duration:20.14 Step:764 CStep:91875\n",
            "Episode:105 Time:20:09:59 Reward:-21.00 Loss:22.88 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.40 Duration:24.94 Step:946 CStep:92822\n",
            "Episode:106 Time:20:10:20 Reward:-21.00 Loss:17.98 Last_100_Avg_Rew:-20.740 Avg_Max_Q:0.000 Epsilon:0.39 Duration:20.09 Step:764 CStep:93587\n",
            "Episode:107 Time:20:10:48 Reward:-19.00 Loss:26.09 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.39 Duration:28.69 Step:1093 CStep:94681\n",
            "Episode:108 Time:20:11:12 Reward:-21.00 Loss:21.08 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.38 Duration:23.36 Step:887 CStep:95569\n",
            "Episode:109 Time:20:11:42 Reward:-21.00 Loss:27.62 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.38 Duration:30.48 Step:1152 CStep:96722\n",
            "Episode:110 Time:20:12:08 Reward:-20.00 Loss:23.52 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.38 Duration:26.04 Step:992 CStep:97715\n",
            "Episode:111 Time:20:12:34 Reward:-20.00 Loss:23.77 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.37 Duration:25.63 Step:979 CStep:98695\n",
            "Episode:112 Time:20:12:57 Reward:-21.00 Loss:20.84 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.37 Duration:22.91 Step:852 CStep:99548\n",
            "Episode:113 Time:20:13:17 Reward:-21.00 Loss:17.27 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.37 Duration:20.35 Step:764 CStep:100313\n",
            "Episode:114 Time:20:13:44 Reward:-20.00 Loss:24.06 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.36 Duration:27.22 Step:1020 CStep:101334\n",
            "Episode:115 Time:20:14:08 Reward:-21.00 Loss:21.28 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.36 Duration:23.91 Step:886 CStep:102221\n",
            "Episode:116 Time:20:14:33 Reward:-21.00 Loss:22.41 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.36 Duration:25.32 Step:946 CStep:103168\n",
            "Episode:117 Time:20:14:57 Reward:-21.00 Loss:21.20 Last_100_Avg_Rew:-20.710 Avg_Max_Q:0.000 Epsilon:0.35 Duration:23.79 Step:884 CStep:104053\n",
            "Episode:118 Time:20:15:28 Reward:-20.00 Loss:27.49 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.35 Duration:30.67 Step:1143 CStep:105197\n",
            "Episode:119 Time:20:15:59 Reward:-20.00 Loss:26.32 Last_100_Avg_Rew:-20.690 Avg_Max_Q:0.000 Epsilon:0.34 Duration:30.64 Step:1129 CStep:106327\n",
            "Episode:120 Time:20:16:24 Reward:-20.00 Loss:21.99 Last_100_Avg_Rew:-20.690 Avg_Max_Q:0.000 Epsilon:0.34 Duration:25.04 Step:934 CStep:107262\n",
            "Episode:121 Time:20:16:49 Reward:-21.00 Loss:21.61 Last_100_Avg_Rew:-20.690 Avg_Max_Q:0.000 Epsilon:0.34 Duration:25.51 Step:944 CStep:108207\n",
            "Episode:122 Time:20:17:10 Reward:-21.00 Loss:17.91 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.34 Duration:20.68 Step:764 CStep:108972\n",
            "Episode:123 Time:20:17:30 Reward:-21.00 Loss:18.38 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.33 Duration:20.56 Step:764 CStep:109737\n",
            "Episode:124 Time:20:17:54 Reward:-21.00 Loss:20.81 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.33 Duration:23.81 Step:884 CStep:110622\n",
            "Episode:125 Time:20:18:15 Reward:-21.00 Loss:18.25 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.33 Duration:20.59 Step:764 CStep:111387\n",
            "Episode:126 Time:20:18:39 Reward:-21.00 Loss:20.59 Last_100_Avg_Rew:-20.700 Avg_Max_Q:0.000 Epsilon:0.32 Duration:23.97 Step:884 CStep:112272\n",
            "Episode:127 Time:20:18:59 Reward:-21.00 Loss:17.85 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.32 Duration:20.57 Step:764 CStep:113037\n",
            "Episode:128 Time:20:19:23 Reward:-21.00 Loss:20.98 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.32 Duration:24.01 Step:880 CStep:113918\n",
            "Episode:129 Time:20:19:45 Reward:-21.00 Loss:19.05 Last_100_Avg_Rew:-20.720 Avg_Max_Q:0.000 Epsilon:0.32 Duration:21.28 Step:792 CStep:114711\n",
            "Episode:130 Time:20:20:18 Reward:-21.00 Loss:28.95 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.31 Duration:33.45 Step:1240 CStep:115952\n",
            "Episode:131 Time:20:20:42 Reward:-21.00 Loss:20.91 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.31 Duration:23.83 Step:884 CStep:116837\n",
            "Episode:132 Time:20:21:03 Reward:-21.00 Loss:17.98 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.31 Duration:20.68 Step:764 CStep:117602\n",
            "Episode:133 Time:20:21:27 Reward:-21.00 Loss:20.69 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.31 Duration:23.96 Step:884 CStep:118487\n",
            "Episode:134 Time:20:21:56 Reward:-21.00 Loss:25.79 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.30 Duration:29.41 Step:1087 CStep:119575\n",
            "Episode:135 Time:20:22:19 Reward:-21.00 Loss:20.19 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.30 Duration:23.04 Step:852 CStep:120428\n",
            "Episode:136 Time:20:22:45 Reward:-21.00 Loss:22.49 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.30 Duration:25.81 Step:944 CStep:121373\n",
            "Episode:137 Time:20:23:09 Reward:-21.00 Loss:21.05 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.29 Duration:23.74 Step:884 CStep:122258\n",
            "Episode:138 Time:20:23:35 Reward:-21.00 Loss:23.21 Last_100_Avg_Rew:-20.730 Avg_Max_Q:0.000 Epsilon:0.29 Duration:26.13 Step:972 CStep:123231\n",
            "Episode:139 Time:20:23:58 Reward:-21.00 Loss:21.71 Last_100_Avg_Rew:-20.740 Avg_Max_Q:0.000 Epsilon:0.29 Duration:23.76 Step:884 CStep:124116\n",
            "Episode:140 Time:20:24:24 Reward:-21.00 Loss:22.62 Last_100_Avg_Rew:-20.750 Avg_Max_Q:0.000 Epsilon:0.28 Duration:25.32 Step:944 CStep:125061\n",
            "Episode:141 Time:20:24:51 Reward:-21.00 Loss:23.23 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.28 Duration:26.92 Step:1006 CStep:126068\n",
            "Episode:142 Time:20:25:14 Reward:-21.00 Loss:20.61 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.28 Duration:23.74 Step:884 CStep:126953\n",
            "Episode:143 Time:20:25:39 Reward:-21.00 Loss:20.46 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.28 Duration:24.71 Step:910 CStep:127864\n",
            "Episode:144 Time:20:26:03 Reward:-21.00 Loss:20.38 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.28 Duration:23.88 Step:884 CStep:128749\n",
            "Episode:145 Time:20:26:24 Reward:-21.00 Loss:17.72 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.27 Duration:20.77 Step:764 CStep:129514\n",
            "Episode:146 Time:20:26:48 Reward:-20.00 Loss:20.95 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.27 Duration:24.35 Step:902 CStep:130417\n",
            "Episode:147 Time:20:27:15 Reward:-21.00 Loss:23.91 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.27 Duration:26.66 Step:991 CStep:131409\n",
            "Episode:148 Time:20:27:35 Reward:-21.00 Loss:18.68 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.27 Duration:20.66 Step:764 CStep:132174\n",
            "Episode:149 Time:20:28:06 Reward:-20.00 Loss:26.86 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.26 Duration:30.53 Step:1127 CStep:133302\n",
            "Episode:150 Time:20:28:38 Reward:-21.00 Loss:28.62 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.26 Duration:32.47 Step:1186 CStep:134489\n",
            "Episode:151 Time:20:29:13 Reward:-21.00 Loss:28.70 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.26 Duration:34.09 Step:1248 CStep:135738\n",
            "Episode:152 Time:20:29:34 Reward:-21.00 Loss:16.88 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.25 Duration:20.96 Step:764 CStep:136503\n",
            "Episode:153 Time:20:29:54 Reward:-21.00 Loss:18.46 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.25 Duration:20.81 Step:764 CStep:137268\n",
            "Episode:154 Time:20:30:19 Reward:-20.00 Loss:21.30 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.25 Duration:24.68 Step:902 CStep:138171\n",
            "Episode:155 Time:20:30:40 Reward:-21.00 Loss:17.72 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.25 Duration:20.60 Step:764 CStep:138936\n",
            "Episode:156 Time:20:31:00 Reward:-21.00 Loss:17.86 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.25 Duration:20.69 Step:764 CStep:139701\n",
            "Episode:157 Time:20:31:29 Reward:-21.00 Loss:24.77 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.24 Duration:28.99 Step:1064 CStep:140766\n",
            "Episode:158 Time:20:31:52 Reward:-21.00 Loss:19.73 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.24 Duration:22.29 Step:824 CStep:141591\n",
            "Episode:159 Time:20:32:15 Reward:-20.00 Loss:19.48 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.24 Duration:22.96 Step:842 CStep:142434\n",
            "Episode:160 Time:20:32:39 Reward:-21.00 Loss:20.88 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.24 Duration:24.76 Step:912 CStep:143347\n",
            "Episode:161 Time:20:33:00 Reward:-21.00 Loss:17.40 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.24 Duration:20.67 Step:764 CStep:144112\n",
            "Episode:162 Time:20:33:24 Reward:-21.00 Loss:21.24 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.24 Duration:23.74 Step:884 CStep:144997\n",
            "Episode:163 Time:20:33:52 Reward:-20.00 Loss:24.60 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.23 Duration:28.30 Step:1058 CStep:146056\n",
            "Episode:164 Time:20:34:13 Reward:-21.00 Loss:18.11 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.23 Duration:20.45 Step:764 CStep:146821\n",
            "Episode:165 Time:20:34:37 Reward:-21.00 Loss:20.52 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.23 Duration:24.04 Step:884 CStep:147706\n",
            "Episode:166 Time:20:34:59 Reward:-21.00 Loss:18.27 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.23 Duration:22.28 Step:824 CStep:148531\n",
            "Episode:167 Time:20:35:19 Reward:-21.00 Loss:17.15 Last_100_Avg_Rew:-20.760 Avg_Max_Q:0.000 Epsilon:0.22 Duration:20.59 Step:764 CStep:149296\n",
            "Episode:168 Time:20:35:42 Reward:-21.00 Loss:20.04 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.22 Duration:22.28 Step:824 CStep:150121\n",
            "Episode:169 Time:20:36:02 Reward:-21.00 Loss:18.14 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.22 Duration:20.70 Step:764 CStep:150886\n",
            "Episode:170 Time:20:36:25 Reward:-21.00 Loss:19.48 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.22 Duration:22.21 Step:824 CStep:151711\n",
            "Episode:171 Time:20:36:55 Reward:-21.00 Loss:26.53 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.22 Duration:30.34 Step:1124 CStep:152836\n",
            "Episode:172 Time:20:37:17 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.21 Duration:22.09 Step:824 CStep:153661\n",
            "Episode:173 Time:20:37:46 Reward:-21.00 Loss:24.03 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.21 Duration:28.64 Step:1064 CStep:154726\n",
            "Episode:174 Time:20:38:13 Reward:-21.00 Loss:24.59 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.21 Duration:26.92 Step:1004 CStep:155731\n",
            "Episode:175 Time:20:38:36 Reward:-21.00 Loss:21.20 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.21 Duration:23.83 Step:884 CStep:156616\n",
            "Episode:176 Time:20:38:59 Reward:-21.00 Loss:18.86 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.21 Duration:22.26 Step:824 CStep:157441\n",
            "Episode:177 Time:20:39:22 Reward:-21.00 Loss:19.25 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.20 Duration:22.97 Step:824 CStep:158266\n",
            "Episode:178 Time:20:39:43 Reward:-21.00 Loss:18.19 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.20 Duration:21.02 Step:764 CStep:159031\n",
            "Episode:179 Time:20:40:12 Reward:-20.00 Loss:25.96 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.20 Duration:29.59 Step:1085 CStep:160117\n",
            "Episode:180 Time:20:40:39 Reward:-21.00 Loss:23.88 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.20 Duration:26.45 Step:972 CStep:161090\n",
            "Episode:181 Time:20:41:01 Reward:-21.00 Loss:18.94 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.20 Duration:22.51 Step:824 CStep:161915\n",
            "Episode:182 Time:20:41:27 Reward:-21.00 Loss:21.66 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.20 Duration:25.74 Step:945 CStep:162861\n",
            "Episode:183 Time:20:41:48 Reward:-21.00 Loss:17.57 Last_100_Avg_Rew:-20.810 Avg_Max_Q:0.000 Epsilon:0.19 Duration:21.13 Step:764 CStep:163626\n",
            "Episode:184 Time:20:42:15 Reward:-20.00 Loss:22.75 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.19 Duration:26.77 Step:979 CStep:164606\n",
            "Episode:185 Time:20:42:39 Reward:-21.00 Loss:20.41 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.19 Duration:23.86 Step:884 CStep:165491\n",
            "Episode:186 Time:20:43:02 Reward:-21.00 Loss:21.27 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.19 Duration:23.62 Step:884 CStep:166376\n",
            "Episode:187 Time:20:43:24 Reward:-21.00 Loss:19.11 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.19 Duration:22.07 Step:824 CStep:167201\n",
            "Episode:188 Time:20:43:55 Reward:-20.00 Loss:26.93 Last_100_Avg_Rew:-20.790 Avg_Max_Q:0.000 Epsilon:0.18 Duration:30.69 Step:1144 CStep:168346\n",
            "Episode:189 Time:20:44:22 Reward:-20.00 Loss:23.33 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.18 Duration:26.38 Step:991 CStep:169338\n",
            "Episode:190 Time:20:44:44 Reward:-21.00 Loss:19.02 Last_100_Avg_Rew:-20.780 Avg_Max_Q:0.000 Epsilon:0.18 Duration:22.13 Step:824 CStep:170163\n",
            "Episode:191 Time:20:45:12 Reward:-20.00 Loss:25.13 Last_100_Avg_Rew:-20.770 Avg_Max_Q:0.000 Epsilon:0.18 Duration:28.73 Step:1069 CStep:171233\n",
            "Episode:192 Time:20:45:33 Reward:-21.00 Loss:18.32 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.18 Duration:20.63 Step:764 CStep:171998\n",
            "Episode:193 Time:20:46:03 Reward:-21.00 Loss:25.96 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.18 Duration:30.19 Step:1126 CStep:173125\n",
            "Episode:194 Time:20:46:24 Reward:-21.00 Loss:18.37 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.18 Duration:20.40 Step:764 CStep:173890\n",
            "Episode:195 Time:20:46:51 Reward:-21.00 Loss:23.83 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:27.01 Step:1004 CStep:174895\n",
            "Episode:196 Time:20:47:13 Reward:-21.00 Loss:19.76 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:22.26 Step:824 CStep:175720\n",
            "Episode:197 Time:20:47:35 Reward:-21.00 Loss:19.12 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:21.94 Step:824 CStep:176545\n",
            "Episode:198 Time:20:48:04 Reward:-21.00 Loss:24.84 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:28.74 Step:1064 CStep:177610\n",
            "Episode:199 Time:20:48:24 Reward:-21.00 Loss:17.72 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:20.47 Step:764 CStep:178375\n",
            "Episode:200 Time:20:48:45 Reward:-21.00 Loss:18.22 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:20.46 Step:764 CStep:179140\n",
            "Episode:201 Time:20:49:05 Reward:-21.00 Loss:17.32 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.17 Duration:20.44 Step:764 CStep:179905\n",
            "Episode:202 Time:20:49:29 Reward:-21.00 Loss:20.38 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.16 Duration:23.79 Step:886 CStep:180792\n",
            "Episode:203 Time:20:49:49 Reward:-21.00 Loss:18.18 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.16 Duration:20.51 Step:764 CStep:181557\n",
            "Episode:204 Time:20:50:10 Reward:-21.00 Loss:18.53 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.16 Duration:20.68 Step:764 CStep:182322\n",
            "Episode:205 Time:20:50:35 Reward:-21.00 Loss:22.41 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.16 Duration:25.42 Step:944 CStep:183267\n",
            "Episode:206 Time:20:51:01 Reward:-21.00 Loss:22.35 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.000 Epsilon:0.16 Duration:25.41 Step:944 CStep:184212\n",
            "Episode:207 Time:20:51:21 Reward:-21.00 Loss:17.56 Last_100_Avg_Rew:-20.840 Avg_Max_Q:0.000 Epsilon:0.16 Duration:20.58 Step:764 CStep:184977\n",
            "Episode:208 Time:20:51:47 Reward:-21.00 Loss:22.80 Last_100_Avg_Rew:-20.840 Avg_Max_Q:0.000 Epsilon:0.16 Duration:25.50 Step:944 CStep:185922\n",
            "Episode:209 Time:20:52:09 Reward:-21.00 Loss:19.95 Last_100_Avg_Rew:-20.840 Avg_Max_Q:0.000 Epsilon:0.15 Duration:22.33 Step:824 CStep:186747\n",
            "Episode:210 Time:20:52:30 Reward:-21.00 Loss:18.65 Last_100_Avg_Rew:-20.850 Avg_Max_Q:0.000 Epsilon:0.15 Duration:20.50 Step:764 CStep:187512\n",
            "Episode:211 Time:20:52:57 Reward:-21.00 Loss:23.91 Last_100_Avg_Rew:-20.860 Avg_Max_Q:0.000 Epsilon:0.15 Duration:27.03 Step:1004 CStep:188517\n",
            "Episode:212 Time:20:53:21 Reward:-21.00 Loss:21.16 Last_100_Avg_Rew:-20.860 Avg_Max_Q:0.000 Epsilon:0.15 Duration:23.84 Step:885 CStep:189403\n",
            "Episode:213 Time:20:53:41 Reward:-21.00 Loss:17.61 Last_100_Avg_Rew:-20.860 Avg_Max_Q:0.000 Epsilon:0.15 Duration:20.64 Step:764 CStep:190168\n",
            "Episode:214 Time:20:54:02 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.15 Duration:20.77 Step:764 CStep:190933\n",
            "Episode:215 Time:20:54:24 Reward:-21.00 Loss:20.20 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.15 Duration:22.35 Step:824 CStep:191758\n",
            "Episode:216 Time:20:54:50 Reward:-21.00 Loss:22.69 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.15 Duration:25.60 Step:944 CStep:192703\n",
            "Episode:217 Time:20:55:12 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.14 Duration:22.29 Step:824 CStep:193528\n",
            "Episode:218 Time:20:55:38 Reward:-21.00 Loss:23.21 Last_100_Avg_Rew:-20.880 Avg_Max_Q:0.000 Epsilon:0.14 Duration:25.62 Step:944 CStep:194473\n",
            "Episode:219 Time:20:56:13 Reward:-20.00 Loss:30.54 Last_100_Avg_Rew:-20.880 Avg_Max_Q:0.000 Epsilon:0.14 Duration:34.94 Step:1279 CStep:195753\n",
            "Episode:220 Time:20:56:34 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.14 Duration:20.80 Step:764 CStep:196518\n",
            "Episode:221 Time:20:56:58 Reward:-21.00 Loss:21.21 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.14 Duration:23.96 Step:884 CStep:197403\n",
            "Episode:222 Time:20:57:23 Reward:-21.00 Loss:22.28 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.14 Duration:25.60 Step:940 CStep:198344\n",
            "Episode:223 Time:20:57:46 Reward:-21.00 Loss:19.89 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.14 Duration:22.45 Step:824 CStep:199169\n",
            "Episode:224 Time:20:58:06 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.14 Duration:20.73 Step:764 CStep:199934\n",
            "Episode:225 Time:20:58:34 Reward:-21.00 Loss:23.81 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:27.27 Step:1006 CStep:200941\n",
            "Episode:226 Time:20:58:58 Reward:-21.00 Loss:20.63 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:24.31 Step:884 CStep:201826\n",
            "Episode:227 Time:20:59:19 Reward:-21.00 Loss:17.93 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:21.09 Step:764 CStep:202591\n",
            "Episode:228 Time:20:59:40 Reward:-21.00 Loss:18.39 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:20.86 Step:764 CStep:203356\n",
            "Episode:229 Time:21:00:02 Reward:-21.00 Loss:19.84 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:22.37 Step:824 CStep:204181\n",
            "Episode:230 Time:21:00:24 Reward:-21.00 Loss:17.79 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:21.39 Step:764 CStep:204946\n",
            "Episode:231 Time:21:00:47 Reward:-21.00 Loss:20.19 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:22.86 Step:824 CStep:205771\n",
            "Episode:232 Time:21:01:09 Reward:-21.00 Loss:18.82 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.13 Duration:22.10 Step:792 CStep:206564\n",
            "Episode:233 Time:21:01:40 Reward:-21.00 Loss:27.02 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.12 Duration:31.29 Step:1124 CStep:207689\n",
            "Episode:234 Time:21:02:05 Reward:-21.00 Loss:20.86 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.12 Duration:24.64 Step:884 CStep:208574\n",
            "Episode:235 Time:21:02:28 Reward:-21.00 Loss:19.93 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.12 Duration:23.11 Step:824 CStep:209399\n",
            "Episode:236 Time:21:02:54 Reward:-21.00 Loss:22.47 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.12 Duration:26.25 Step:944 CStep:210344\n",
            "Episode:237 Time:21:03:18 Reward:-21.00 Loss:20.66 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.12 Duration:24.41 Step:884 CStep:211229\n",
            "Episode:238 Time:21:03:45 Reward:-19.00 Loss:23.05 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.12 Duration:27.00 Step:999 CStep:212229\n",
            "Episode:239 Time:21:04:06 Reward:-21.00 Loss:18.17 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.12 Duration:20.30 Step:764 CStep:212994\n",
            "Episode:240 Time:21:04:26 Reward:-21.00 Loss:17.94 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.12 Duration:20.18 Step:764 CStep:213759\n",
            "Episode:241 Time:21:04:48 Reward:-21.00 Loss:20.10 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.12 Duration:22.00 Step:824 CStep:214584\n",
            "Episode:242 Time:21:05:10 Reward:-21.00 Loss:19.73 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.12 Duration:22.00 Step:824 CStep:215409\n",
            "Episode:243 Time:21:05:41 Reward:-21.00 Loss:29.12 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.11 Duration:31.44 Step:1186 CStep:216596\n",
            "Episode:244 Time:21:06:03 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.11 Duration:22.11 Step:824 CStep:217421\n",
            "Episode:245 Time:21:06:24 Reward:-21.00 Loss:18.48 Last_100_Avg_Rew:-20.870 Avg_Max_Q:0.000 Epsilon:0.11 Duration:20.64 Step:764 CStep:218186\n",
            "Episode:246 Time:21:06:48 Reward:-21.00 Loss:20.98 Last_100_Avg_Rew:-20.880 Avg_Max_Q:0.000 Epsilon:0.11 Duration:23.56 Step:884 CStep:219071\n",
            "Episode:247 Time:21:07:10 Reward:-21.00 Loss:19.52 Last_100_Avg_Rew:-20.880 Avg_Max_Q:0.000 Epsilon:0.11 Duration:22.10 Step:824 CStep:219896\n",
            "Episode:248 Time:21:07:30 Reward:-21.00 Loss:18.45 Last_100_Avg_Rew:-20.880 Avg_Max_Q:0.000 Epsilon:0.11 Duration:20.44 Step:764 CStep:220661\n",
            "Episode:249 Time:21:07:55 Reward:-21.00 Loss:22.99 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.11 Duration:25.14 Step:944 CStep:221606\n",
            "Episode:250 Time:21:08:17 Reward:-21.00 Loss:20.03 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.11 Duration:21.99 Step:824 CStep:222431\n",
            "Episode:251 Time:21:08:39 Reward:-21.00 Loss:20.18 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.11 Duration:21.91 Step:824 CStep:223256\n",
            "Episode:252 Time:21:09:01 Reward:-21.00 Loss:20.24 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.11 Duration:21.94 Step:824 CStep:224081\n",
            "Episode:253 Time:21:09:29 Reward:-21.00 Loss:24.35 Last_100_Avg_Rew:-20.890 Avg_Max_Q:0.000 Epsilon:0.10 Duration:27.58 Step:1032 CStep:225114\n",
            "Episode:254 Time:21:09:51 Reward:-21.00 Loss:20.59 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.10 Duration:22.75 Step:852 CStep:225967\n",
            "Episode:255 Time:21:10:13 Reward:-21.00 Loss:20.09 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.10 Duration:21.92 Step:824 CStep:226792\n",
            "Episode:256 Time:21:10:40 Reward:-21.00 Loss:24.58 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.10 Duration:26.61 Step:1006 CStep:227799\n",
            "Episode:257 Time:21:11:05 Reward:-21.00 Loss:22.66 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.10 Duration:25.23 Step:946 CStep:228746\n",
            "Episode:258 Time:21:11:29 Reward:-21.00 Loss:20.49 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.10 Duration:23.72 Step:884 CStep:229631\n",
            "Episode:259 Time:21:11:49 Reward:-21.00 Loss:18.11 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.10 Duration:20.46 Step:764 CStep:230396\n",
            "Episode:260 Time:21:12:15 Reward:-21.00 Loss:23.02 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.10 Duration:25.41 Step:945 CStep:231342\n",
            "Episode:261 Time:21:12:43 Reward:-21.00 Loss:25.52 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.10 Duration:27.89 Step:1032 CStep:232375\n",
            "Episode:262 Time:21:13:22 Reward:-21.00 Loss:36.02 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.10 Duration:39.41 Step:1485 CStep:233861\n",
            "Episode:263 Time:21:13:43 Reward:-21.00 Loss:18.71 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.10 Duration:20.46 Step:764 CStep:234626\n",
            "Episode:264 Time:21:14:06 Reward:-21.00 Loss:20.06 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:23.83 Step:884 CStep:235511\n",
            "Episode:265 Time:21:14:30 Reward:-21.00 Loss:21.34 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:23.69 Step:884 CStep:236396\n",
            "Episode:266 Time:21:14:52 Reward:-21.00 Loss:19.91 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:22.03 Step:824 CStep:237221\n",
            "Episode:267 Time:21:15:14 Reward:-21.00 Loss:19.83 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:22.21 Step:824 CStep:238046\n",
            "Episode:268 Time:21:15:37 Reward:-21.00 Loss:19.86 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:22.85 Step:852 CStep:238899\n",
            "Episode:269 Time:21:15:59 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:21.87 Step:824 CStep:239724\n",
            "Episode:270 Time:21:16:20 Reward:-21.00 Loss:18.36 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:20.47 Step:764 CStep:240489\n",
            "Episode:271 Time:21:16:42 Reward:-21.00 Loss:19.87 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.09 Duration:22.19 Step:824 CStep:241314\n",
            "Episode:272 Time:21:17:10 Reward:-20.00 Loss:24.98 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.09 Duration:27.90 Step:1040 CStep:242355\n",
            "Episode:273 Time:21:17:32 Reward:-21.00 Loss:18.92 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.09 Duration:22.07 Step:824 CStep:243180\n",
            "Episode:274 Time:21:18:02 Reward:-21.00 Loss:26.49 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.09 Duration:30.52 Step:1124 CStep:244305\n",
            "Episode:275 Time:21:18:28 Reward:-21.00 Loss:22.39 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.09 Duration:25.83 Step:944 CStep:245250\n",
            "Episode:276 Time:21:18:52 Reward:-21.00 Loss:21.46 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:24.17 Step:884 CStep:246135\n",
            "Episode:277 Time:21:19:26 Reward:-20.00 Loss:28.52 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.08 Duration:33.38 Step:1222 CStep:247358\n",
            "Episode:278 Time:21:19:47 Reward:-21.00 Loss:18.04 Last_100_Avg_Rew:-20.900 Avg_Max_Q:0.000 Epsilon:0.08 Duration:20.91 Step:764 CStep:248123\n",
            "Episode:279 Time:21:20:07 Reward:-21.00 Loss:18.60 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:20.92 Step:764 CStep:248888\n",
            "Episode:280 Time:21:20:30 Reward:-21.00 Loss:19.94 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:22.44 Step:824 CStep:249713\n",
            "Episode:281 Time:21:20:50 Reward:-21.00 Loss:17.60 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:20.35 Step:764 CStep:250478\n",
            "Episode:282 Time:21:21:17 Reward:-21.00 Loss:24.34 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:26.59 Step:1004 CStep:251483\n",
            "Episode:283 Time:21:21:42 Reward:-21.00 Loss:22.54 Last_100_Avg_Rew:-20.910 Avg_Max_Q:0.000 Epsilon:0.08 Duration:25.20 Step:944 CStep:252428\n",
            "Episode:284 Time:21:22:02 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.08 Duration:20.26 Step:764 CStep:253193\n",
            "Episode:285 Time:21:22:26 Reward:-21.00 Loss:21.30 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.08 Duration:23.49 Step:884 CStep:254078\n",
            "Episode:286 Time:21:22:48 Reward:-21.00 Loss:19.99 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.08 Duration:21.93 Step:824 CStep:254903\n",
            "Episode:287 Time:21:23:08 Reward:-21.00 Loss:18.18 Last_100_Avg_Rew:-20.920 Avg_Max_Q:0.000 Epsilon:0.08 Duration:20.20 Step:764 CStep:255668\n",
            "Episode:288 Time:21:23:30 Reward:-21.00 Loss:19.88 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.08 Duration:21.89 Step:824 CStep:256493\n",
            "Episode:289 Time:21:23:54 Reward:-21.00 Loss:20.41 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.08 Duration:23.67 Step:884 CStep:257378\n",
            "Episode:290 Time:21:24:14 Reward:-21.00 Loss:18.35 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.51 Step:764 CStep:258143\n",
            "Episode:291 Time:21:24:36 Reward:-21.00 Loss:19.75 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:21.97 Step:824 CStep:258968\n",
            "Episode:292 Time:21:24:59 Reward:-21.00 Loss:21.18 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:23.47 Step:884 CStep:259853\n",
            "Episode:293 Time:21:25:21 Reward:-21.00 Loss:19.34 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:21.82 Step:824 CStep:260678\n",
            "Episode:294 Time:21:25:42 Reward:-21.00 Loss:18.46 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.49 Step:764 CStep:261443\n",
            "Episode:295 Time:21:26:02 Reward:-21.00 Loss:18.16 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.30 Step:764 CStep:262208\n",
            "Episode:296 Time:21:26:24 Reward:-21.00 Loss:19.92 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:21.78 Step:824 CStep:263033\n",
            "Episode:297 Time:21:26:46 Reward:-21.00 Loss:19.98 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:21.93 Step:824 CStep:263858\n",
            "Episode:298 Time:21:27:06 Reward:-21.00 Loss:18.55 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.39 Step:764 CStep:264623\n",
            "Episode:299 Time:21:27:29 Reward:-21.00 Loss:21.31 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:23.30 Step:884 CStep:265508\n",
            "Episode:300 Time:21:27:51 Reward:-21.00 Loss:20.03 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:21.73 Step:824 CStep:266333\n",
            "Episode:301 Time:21:28:16 Reward:-21.00 Loss:22.19 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:25.19 Step:944 CStep:267278\n",
            "Episode:302 Time:21:28:37 Reward:-21.00 Loss:18.34 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.25 Step:764 CStep:268043\n",
            "Episode:303 Time:21:28:57 Reward:-21.00 Loss:18.34 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:20.41 Step:764 CStep:268808\n",
            "Episode:304 Time:21:29:25 Reward:-21.00 Loss:26.50 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:28.14 Step:1064 CStep:269873\n",
            "Episode:305 Time:21:29:49 Reward:-21.00 Loss:21.10 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:23.45 Step:884 CStep:270758\n",
            "Episode:306 Time:21:30:11 Reward:-21.00 Loss:20.37 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.07 Duration:22.50 Step:852 CStep:271611\n",
            "Episode:307 Time:21:30:31 Reward:-21.00 Loss:18.53 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:20.19 Step:764 CStep:272376\n",
            "Episode:308 Time:21:30:53 Reward:-21.00 Loss:19.40 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:22.00 Step:824 CStep:273201\n",
            "Episode:309 Time:21:31:14 Reward:-21.00 Loss:18.60 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:20.55 Step:764 CStep:273966\n",
            "Episode:310 Time:21:31:35 Reward:-21.00 Loss:18.00 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.03 Step:764 CStep:274731\n",
            "Episode:311 Time:21:31:57 Reward:-21.00 Loss:19.67 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:22.21 Step:824 CStep:275556\n",
            "Episode:312 Time:21:32:17 Reward:-21.00 Loss:18.54 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:20.17 Step:764 CStep:276321\n",
            "Episode:313 Time:21:32:39 Reward:-21.00 Loss:19.40 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.99 Step:824 CStep:277146\n",
            "Episode:314 Time:21:33:09 Reward:-21.00 Loss:26.81 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:30.13 Step:1120 CStep:278267\n",
            "Episode:315 Time:21:33:31 Reward:-21.00 Loss:20.12 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.99 Step:824 CStep:279092\n",
            "Episode:316 Time:21:33:52 Reward:-21.00 Loss:18.96 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:20.31 Step:764 CStep:279857\n",
            "Episode:317 Time:21:34:17 Reward:-21.00 Loss:23.19 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:25.11 Step:944 CStep:280802\n",
            "Episode:318 Time:21:34:39 Reward:-21.00 Loss:19.32 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.84 Step:824 CStep:281627\n",
            "Episode:319 Time:21:35:04 Reward:-21.00 Loss:22.77 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:24.92 Step:944 CStep:282572\n",
            "Episode:320 Time:21:35:26 Reward:-21.00 Loss:19.73 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.89 Step:824 CStep:283397\n",
            "Episode:321 Time:21:35:49 Reward:-21.00 Loss:21.87 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:23.29 Step:884 CStep:284282\n",
            "Episode:322 Time:21:36:15 Reward:-21.00 Loss:23.88 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:26.52 Step:1004 CStep:285287\n",
            "Episode:323 Time:21:36:37 Reward:-21.00 Loss:20.46 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.79 Step:824 CStep:286112\n",
            "Episode:324 Time:21:36:57 Reward:-21.00 Loss:18.61 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:20.20 Step:764 CStep:286877\n",
            "Episode:325 Time:21:37:21 Reward:-21.00 Loss:22.15 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:23.45 Step:884 CStep:287762\n",
            "Episode:326 Time:21:37:43 Reward:-21.00 Loss:19.76 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.06 Duration:21.79 Step:824 CStep:288587\n",
            "Episode:327 Time:21:38:08 Reward:-21.00 Loss:23.49 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.00 Step:944 CStep:289532\n",
            "Episode:328 Time:21:38:34 Reward:-21.00 Loss:24.41 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.72 Step:1004 CStep:290537\n",
            "Episode:329 Time:21:38:55 Reward:-21.00 Loss:19.31 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:291302\n",
            "Episode:330 Time:21:39:22 Reward:-21.00 Loss:25.98 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.88 Step:1004 CStep:292307\n",
            "Episode:331 Time:21:39:42 Reward:-21.00 Loss:19.02 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.58 Step:764 CStep:293072\n",
            "Episode:332 Time:21:40:03 Reward:-21.00 Loss:19.24 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:293837\n",
            "Episode:333 Time:21:40:23 Reward:-21.00 Loss:18.59 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.43 Step:764 CStep:294602\n",
            "Episode:334 Time:21:40:44 Reward:-21.00 Loss:19.66 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.50 Step:764 CStep:295367\n",
            "Episode:335 Time:21:41:06 Reward:-21.00 Loss:19.95 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.17 Step:824 CStep:296192\n",
            "Episode:336 Time:21:41:28 Reward:-21.00 Loss:20.25 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.16 Step:824 CStep:297017\n",
            "Episode:337 Time:21:41:54 Reward:-20.00 Loss:24.70 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.37 Step:979 CStep:297997\n",
            "Episode:338 Time:21:42:19 Reward:-21.00 Loss:21.52 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.32 Step:884 CStep:298882\n",
            "Episode:339 Time:21:42:42 Reward:-21.00 Loss:21.88 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.40 Step:852 CStep:299735\n",
            "Episode:340 Time:21:43:03 Reward:-21.00 Loss:19.38 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.19 Step:764 CStep:300500\n",
            "Episode:341 Time:21:43:26 Reward:-21.00 Loss:20.36 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.67 Step:824 CStep:301325\n",
            "Episode:342 Time:21:43:47 Reward:-21.00 Loss:18.95 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.09 Step:764 CStep:302090\n",
            "Episode:343 Time:21:44:10 Reward:-21.00 Loss:20.64 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.77 Step:824 CStep:302915\n",
            "Episode:344 Time:21:44:34 Reward:-21.00 Loss:21.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.48 Step:884 CStep:303800\n",
            "Episode:345 Time:21:44:55 Reward:-21.00 Loss:18.82 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.18 Step:764 CStep:304565\n",
            "Episode:346 Time:21:45:20 Reward:-21.00 Loss:21.98 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.56 Step:884 CStep:305450\n",
            "Episode:347 Time:21:45:52 Reward:-21.00 Loss:28.31 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:32.54 Step:1184 CStep:306635\n",
            "Episode:348 Time:21:46:14 Reward:-21.00 Loss:19.66 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.23 Step:764 CStep:307400\n",
            "Episode:349 Time:21:46:40 Reward:-21.00 Loss:23.43 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.08 Step:944 CStep:308345\n",
            "Episode:350 Time:21:47:05 Reward:-21.00 Loss:21.43 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.94 Step:884 CStep:309230\n",
            "Episode:351 Time:21:47:26 Reward:-21.00 Loss:18.44 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.67 Step:764 CStep:309995\n",
            "Episode:352 Time:21:47:56 Reward:-21.00 Loss:26.31 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.75 Step:1064 CStep:311060\n",
            "Episode:353 Time:21:48:20 Reward:-21.00 Loss:20.49 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.89 Step:824 CStep:311885\n",
            "Episode:354 Time:21:48:42 Reward:-21.00 Loss:19.34 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.60 Step:764 CStep:312650\n",
            "Episode:355 Time:21:49:03 Reward:-21.00 Loss:18.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.59 Step:764 CStep:313415\n",
            "Episode:356 Time:21:49:34 Reward:-21.00 Loss:27.60 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.23 Step:1124 CStep:314540\n",
            "Episode:357 Time:21:50:01 Reward:-21.00 Loss:23.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.68 Step:944 CStep:315485\n",
            "Episode:358 Time:21:50:22 Reward:-21.00 Loss:18.41 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.32 Step:764 CStep:316250\n",
            "Episode:359 Time:21:50:46 Reward:-21.00 Loss:20.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.73 Step:852 CStep:317103\n",
            "Episode:360 Time:21:51:08 Reward:-21.00 Loss:18.91 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.43 Step:764 CStep:317868\n",
            "Episode:361 Time:21:51:29 Reward:-21.00 Loss:18.22 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.43 Step:764 CStep:318633\n",
            "Episode:362 Time:21:51:55 Reward:-21.00 Loss:23.60 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.34 Step:944 CStep:319578\n",
            "Episode:363 Time:21:52:22 Reward:-21.00 Loss:22.36 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.77 Step:944 CStep:320523\n",
            "Episode:364 Time:21:52:44 Reward:-21.00 Loss:18.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.67 Step:764 CStep:321288\n",
            "Episode:365 Time:21:53:05 Reward:-21.00 Loss:19.13 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.48 Step:764 CStep:322053\n",
            "Episode:366 Time:21:53:28 Reward:-21.00 Loss:19.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.06 Step:824 CStep:322878\n",
            "Episode:367 Time:21:53:50 Reward:-21.00 Loss:18.76 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.32 Step:764 CStep:323643\n",
            "Episode:368 Time:21:54:23 Reward:-19.00 Loss:29.09 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:33.35 Step:1195 CStep:324839\n",
            "Episode:369 Time:21:54:51 Reward:-21.00 Loss:24.07 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.06 Step:1005 CStep:325845\n",
            "Episode:370 Time:21:55:14 Reward:-21.00 Loss:20.57 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.05 Step:824 CStep:326670\n",
            "Episode:371 Time:21:55:39 Reward:-21.00 Loss:21.73 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.74 Step:884 CStep:327555\n",
            "Episode:372 Time:21:56:02 Reward:-21.00 Loss:20.30 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.99 Step:824 CStep:328380\n",
            "Episode:373 Time:21:56:28 Reward:-21.00 Loss:23.71 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.46 Step:944 CStep:329325\n",
            "Episode:374 Time:21:56:50 Reward:-21.00 Loss:18.70 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.40 Step:764 CStep:330090\n",
            "Episode:375 Time:21:57:11 Reward:-21.00 Loss:18.94 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.38 Step:764 CStep:330855\n",
            "Episode:376 Time:21:57:38 Reward:-21.00 Loss:23.04 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.42 Step:944 CStep:331800\n",
            "Episode:377 Time:21:57:59 Reward:-21.00 Loss:18.59 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.50 Step:764 CStep:332565\n",
            "Episode:378 Time:21:58:22 Reward:-21.00 Loss:19.87 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.34 Step:824 CStep:333390\n",
            "Episode:379 Time:21:58:44 Reward:-21.00 Loss:19.52 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.52 Step:764 CStep:334155\n",
            "Episode:380 Time:21:59:09 Reward:-21.00 Loss:21.58 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.72 Step:884 CStep:335040\n",
            "Episode:381 Time:21:59:30 Reward:-21.00 Loss:18.36 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.47 Step:764 CStep:335805\n",
            "Episode:382 Time:21:59:51 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.32 Step:764 CStep:336570\n",
            "Episode:383 Time:22:00:14 Reward:-21.00 Loss:20.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.95 Step:824 CStep:337395\n",
            "Episode:384 Time:22:00:41 Reward:-21.00 Loss:24.07 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.60 Step:944 CStep:338340\n",
            "Episode:385 Time:22:01:07 Reward:-21.00 Loss:23.53 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.44 Step:944 CStep:339285\n",
            "Episode:386 Time:22:01:30 Reward:-21.00 Loss:20.24 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.82 Step:824 CStep:340110\n",
            "Episode:387 Time:22:01:51 Reward:-21.00 Loss:18.59 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.91 Step:764 CStep:340875\n",
            "Episode:388 Time:22:02:14 Reward:-21.00 Loss:20.19 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.74 Step:824 CStep:341700\n",
            "Episode:389 Time:22:02:35 Reward:-21.00 Loss:18.35 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.01 Step:764 CStep:342465\n",
            "Episode:390 Time:22:02:56 Reward:-21.00 Loss:18.37 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.06 Step:764 CStep:343230\n",
            "Episode:391 Time:22:03:19 Reward:-21.00 Loss:20.22 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.83 Step:824 CStep:344055\n",
            "Episode:392 Time:22:03:40 Reward:-21.00 Loss:19.17 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.13 Step:764 CStep:344820\n",
            "Episode:393 Time:22:04:04 Reward:-21.00 Loss:21.74 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.26 Step:884 CStep:345705\n",
            "Episode:394 Time:22:04:30 Reward:-20.00 Loss:22.30 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.31 Step:919 CStep:346625\n",
            "Episode:395 Time:22:04:52 Reward:-21.00 Loss:20.37 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.65 Step:824 CStep:347450\n",
            "Episode:396 Time:22:05:13 Reward:-21.00 Loss:18.86 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.14 Step:764 CStep:348215\n",
            "Episode:397 Time:22:05:38 Reward:-21.00 Loss:22.01 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.35 Step:884 CStep:349100\n",
            "Episode:398 Time:22:05:59 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.92 Step:764 CStep:349865\n",
            "Episode:399 Time:22:06:22 Reward:-21.00 Loss:22.04 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.87 Step:884 CStep:350750\n",
            "Episode:400 Time:22:06:47 Reward:-21.00 Loss:21.73 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.23 Step:884 CStep:351635\n",
            "Episode:401 Time:22:07:07 Reward:-21.00 Loss:19.26 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.72 Step:764 CStep:352400\n",
            "Episode:402 Time:22:07:32 Reward:-21.00 Loss:22.32 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.66 Step:912 CStep:353313\n",
            "Episode:403 Time:22:07:54 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.29 Step:824 CStep:354138\n",
            "Episode:404 Time:22:08:15 Reward:-21.00 Loss:18.27 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.66 Step:764 CStep:354903\n",
            "Episode:405 Time:22:08:36 Reward:-21.00 Loss:18.98 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.05 Step:764 CStep:355668\n",
            "Episode:406 Time:22:08:57 Reward:-21.00 Loss:18.81 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.67 Step:764 CStep:356433\n",
            "Episode:407 Time:22:09:19 Reward:-21.00 Loss:21.17 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.29 Step:824 CStep:357258\n",
            "Episode:408 Time:22:09:40 Reward:-21.00 Loss:19.37 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.85 Step:764 CStep:358023\n",
            "Episode:409 Time:22:10:02 Reward:-21.00 Loss:20.35 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.45 Step:824 CStep:358848\n",
            "Episode:410 Time:22:10:23 Reward:-21.00 Loss:19.14 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.80 Step:764 CStep:359613\n",
            "Episode:411 Time:22:10:47 Reward:-21.00 Loss:22.29 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.13 Step:884 CStep:360498\n",
            "Episode:412 Time:22:11:10 Reward:-21.00 Loss:21.29 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.44 Step:824 CStep:361323\n",
            "Episode:413 Time:22:11:32 Reward:-21.00 Loss:20.34 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.53 Step:824 CStep:362148\n",
            "Episode:414 Time:22:12:01 Reward:-20.00 Loss:26.62 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.47 Step:1039 CStep:363188\n",
            "Episode:415 Time:22:12:22 Reward:-21.00 Loss:19.80 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.10 Step:764 CStep:363953\n",
            "Episode:416 Time:22:12:43 Reward:-21.00 Loss:19.26 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.86 Step:764 CStep:364718\n",
            "Episode:417 Time:22:13:04 Reward:-21.00 Loss:19.14 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.89 Step:764 CStep:365483\n",
            "Episode:418 Time:22:13:28 Reward:-21.00 Loss:22.09 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.23 Step:884 CStep:366368\n",
            "Episode:419 Time:22:13:49 Reward:-21.00 Loss:19.72 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.06 Step:764 CStep:367133\n",
            "Episode:420 Time:22:14:10 Reward:-21.00 Loss:19.61 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.96 Step:764 CStep:367898\n",
            "Episode:421 Time:22:14:32 Reward:-21.00 Loss:20.95 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.55 Step:824 CStep:368723\n",
            "Episode:422 Time:22:14:55 Reward:-21.00 Loss:21.02 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.75 Step:824 CStep:369548\n",
            "Episode:423 Time:22:15:16 Reward:-21.00 Loss:18.65 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.90 Step:764 CStep:370313\n",
            "Episode:424 Time:22:15:37 Reward:-21.00 Loss:18.72 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.88 Step:764 CStep:371078\n",
            "Episode:425 Time:22:15:59 Reward:-21.00 Loss:20.42 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.44 Step:824 CStep:371903\n",
            "Episode:426 Time:22:16:20 Reward:-21.00 Loss:19.23 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.76 Step:764 CStep:372668\n",
            "Episode:427 Time:22:16:43 Reward:-21.00 Loss:21.27 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.61 Step:824 CStep:373493\n",
            "Episode:428 Time:22:17:04 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:374258\n",
            "Episode:429 Time:22:17:29 Reward:-21.00 Loss:24.19 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.72 Step:944 CStep:375203\n",
            "Episode:430 Time:22:17:54 Reward:-21.00 Loss:23.04 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.21 Step:884 CStep:376088\n",
            "Episode:431 Time:22:18:15 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:376853\n",
            "Episode:432 Time:22:18:37 Reward:-21.00 Loss:20.34 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.59 Step:824 CStep:377678\n",
            "Episode:433 Time:22:18:58 Reward:-21.00 Loss:19.81 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.82 Step:764 CStep:378443\n",
            "Episode:434 Time:22:19:19 Reward:-21.00 Loss:19.30 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.09 Step:764 CStep:379208\n",
            "Episode:435 Time:22:19:42 Reward:-21.00 Loss:20.52 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.56 Step:824 CStep:380033\n",
            "Episode:436 Time:22:20:02 Reward:-21.00 Loss:19.41 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.84 Step:764 CStep:380798\n",
            "Episode:437 Time:22:20:23 Reward:-21.00 Loss:19.26 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:381563\n",
            "Episode:438 Time:22:20:46 Reward:-21.00 Loss:21.93 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.56 Step:824 CStep:382388\n",
            "Episode:439 Time:22:21:09 Reward:-21.00 Loss:20.91 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.59 Step:824 CStep:383213\n",
            "Episode:440 Time:22:21:33 Reward:-21.00 Loss:22.85 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.03 Step:884 CStep:384098\n",
            "Episode:441 Time:22:21:54 Reward:-21.00 Loss:19.65 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.95 Step:764 CStep:384863\n",
            "Episode:442 Time:22:22:15 Reward:-21.00 Loss:19.87 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.96 Step:764 CStep:385628\n",
            "Episode:443 Time:22:22:39 Reward:-21.00 Loss:23.34 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.22 Step:884 CStep:386513\n",
            "Episode:444 Time:22:23:03 Reward:-21.00 Loss:22.75 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.15 Step:884 CStep:387398\n",
            "Episode:445 Time:22:23:24 Reward:-21.00 Loss:19.82 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.97 Step:764 CStep:388163\n",
            "Episode:446 Time:22:23:45 Reward:-21.00 Loss:19.77 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.71 Step:764 CStep:388928\n",
            "Episode:447 Time:22:24:09 Reward:-21.00 Loss:22.62 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.14 Step:884 CStep:389813\n",
            "Episode:448 Time:22:24:30 Reward:-21.00 Loss:19.50 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.96 Step:764 CStep:390578\n",
            "Episode:449 Time:22:25:00 Reward:-21.00 Loss:28.71 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.61 Step:1124 CStep:391703\n",
            "Episode:450 Time:22:25:21 Reward:-21.00 Loss:19.54 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.97 Step:764 CStep:392468\n",
            "Episode:451 Time:22:25:44 Reward:-21.00 Loss:21.77 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.60 Step:824 CStep:393293\n",
            "Episode:452 Time:22:26:05 Reward:-21.00 Loss:19.41 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.87 Step:764 CStep:394058\n",
            "Episode:453 Time:22:26:29 Reward:-21.00 Loss:23.12 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.11 Step:884 CStep:394943\n",
            "Episode:454 Time:22:26:50 Reward:-21.00 Loss:19.61 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.86 Step:764 CStep:395708\n",
            "Episode:455 Time:22:27:11 Reward:-21.00 Loss:19.66 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.91 Step:764 CStep:396473\n",
            "Episode:456 Time:22:27:31 Reward:-21.00 Loss:19.48 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.87 Step:764 CStep:397238\n",
            "Episode:457 Time:22:27:52 Reward:-21.00 Loss:19.40 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.98 Step:764 CStep:398003\n",
            "Episode:458 Time:22:28:16 Reward:-21.00 Loss:21.61 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.15 Step:843 CStep:398847\n",
            "Episode:459 Time:22:28:39 Reward:-21.00 Loss:21.31 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.06 Step:824 CStep:399672\n",
            "Episode:460 Time:22:29:02 Reward:-21.00 Loss:20.55 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.94 Step:824 CStep:400497\n",
            "Episode:461 Time:22:29:25 Reward:-21.00 Loss:21.17 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.10 Step:824 CStep:401322\n",
            "Episode:462 Time:22:29:48 Reward:-21.00 Loss:21.42 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.04 Step:824 CStep:402147\n",
            "Episode:463 Time:22:30:09 Reward:-21.00 Loss:19.73 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.24 Step:764 CStep:402912\n",
            "Episode:464 Time:22:30:37 Reward:-21.00 Loss:26.74 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.71 Step:1004 CStep:403917\n",
            "Episode:465 Time:22:31:01 Reward:-21.00 Loss:22.84 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.53 Step:884 CStep:404802\n",
            "Episode:466 Time:22:31:23 Reward:-21.00 Loss:19.54 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.28 Step:764 CStep:405567\n",
            "Episode:467 Time:22:31:47 Reward:-21.00 Loss:21.05 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.03 Step:852 CStep:406420\n",
            "Episode:468 Time:22:32:08 Reward:-21.00 Loss:19.81 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.29 Step:764 CStep:407185\n",
            "Episode:469 Time:22:32:32 Reward:-21.00 Loss:23.02 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.49 Step:886 CStep:408072\n",
            "Episode:470 Time:22:32:53 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.95 Step:764 CStep:408837\n",
            "Episode:471 Time:22:33:14 Reward:-21.00 Loss:19.56 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.12 Step:764 CStep:409602\n",
            "Episode:472 Time:22:33:36 Reward:-21.00 Loss:19.94 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.18 Step:764 CStep:410367\n",
            "Episode:473 Time:22:33:58 Reward:-21.00 Loss:21.53 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.71 Step:824 CStep:411192\n",
            "Episode:474 Time:22:34:19 Reward:-21.00 Loss:20.56 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.15 Step:764 CStep:411957\n",
            "Episode:475 Time:22:34:42 Reward:-21.00 Loss:21.46 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.91 Step:824 CStep:412782\n",
            "Episode:476 Time:22:35:05 Reward:-21.00 Loss:20.36 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.76 Step:824 CStep:413607\n",
            "Episode:477 Time:22:35:26 Reward:-21.00 Loss:19.52 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.31 Step:764 CStep:414372\n",
            "Episode:478 Time:22:35:47 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.02 Step:764 CStep:415137\n",
            "Episode:479 Time:22:36:09 Reward:-21.00 Loss:20.41 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.10 Step:764 CStep:415902\n",
            "Episode:480 Time:22:36:33 Reward:-21.00 Loss:23.54 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.46 Step:884 CStep:416787\n",
            "Episode:481 Time:22:36:56 Reward:-21.00 Loss:21.59 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.66 Step:824 CStep:417612\n",
            "Episode:482 Time:22:37:20 Reward:-21.00 Loss:22.81 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.59 Step:884 CStep:418497\n",
            "Episode:483 Time:22:37:43 Reward:-21.00 Loss:21.41 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.80 Step:824 CStep:419322\n",
            "Episode:484 Time:22:38:04 Reward:-21.00 Loss:19.73 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.00 Step:764 CStep:420087\n",
            "Episode:485 Time:22:38:29 Reward:-21.00 Loss:22.96 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.41 Step:884 CStep:420972\n",
            "Episode:486 Time:22:38:51 Reward:-21.00 Loss:21.85 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.79 Step:824 CStep:421797\n",
            "Episode:487 Time:22:39:12 Reward:-21.00 Loss:19.19 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.01 Step:764 CStep:422562\n",
            "Episode:488 Time:22:39:37 Reward:-21.00 Loss:22.08 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.43 Step:884 CStep:423447\n",
            "Episode:489 Time:22:40:05 Reward:-21.00 Loss:25.48 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.81 Step:1004 CStep:424452\n",
            "Episode:490 Time:22:40:26 Reward:-21.00 Loss:19.91 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.15 Step:764 CStep:425217\n",
            "Episode:491 Time:22:40:47 Reward:-21.00 Loss:19.09 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.23 Step:764 CStep:425982\n",
            "Episode:492 Time:22:41:11 Reward:-21.00 Loss:22.88 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.31 Step:884 CStep:426867\n",
            "Episode:493 Time:22:41:35 Reward:-20.00 Loss:21.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.35 Step:842 CStep:427710\n",
            "Episode:494 Time:22:42:01 Reward:-21.00 Loss:24.73 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.95 Step:944 CStep:428655\n",
            "Episode:495 Time:22:42:22 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.13 Step:764 CStep:429420\n",
            "Episode:496 Time:22:42:43 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.31 Step:764 CStep:430185\n",
            "Episode:497 Time:22:43:04 Reward:-21.00 Loss:19.55 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.91 Step:764 CStep:430950\n",
            "Episode:498 Time:22:43:25 Reward:-21.00 Loss:20.10 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.92 Step:764 CStep:431715\n",
            "Episode:499 Time:22:43:46 Reward:-21.00 Loss:19.86 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.80 Step:764 CStep:432480\n",
            "Episode:500 Time:22:44:07 Reward:-21.00 Loss:19.32 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.95 Step:764 CStep:433245\n",
            "Episode:501 Time:22:44:28 Reward:-21.00 Loss:19.64 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.93 Step:764 CStep:434010\n",
            "Episode:502 Time:22:44:48 Reward:-21.00 Loss:19.59 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.79 Step:764 CStep:434775\n",
            "Episode:503 Time:22:45:09 Reward:-21.00 Loss:18.98 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.97 Step:764 CStep:435540\n",
            "Episode:504 Time:22:45:34 Reward:-21.00 Loss:22.77 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.29 Step:884 CStep:436425\n",
            "Episode:505 Time:22:45:54 Reward:-21.00 Loss:20.02 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.85 Step:764 CStep:437190\n",
            "Episode:506 Time:22:46:20 Reward:-21.00 Loss:24.23 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.86 Step:944 CStep:438135\n",
            "Episode:507 Time:22:46:46 Reward:-21.00 Loss:24.01 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.82 Step:944 CStep:439080\n",
            "Episode:508 Time:22:47:07 Reward:-21.00 Loss:19.63 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:439845\n",
            "Episode:509 Time:22:47:30 Reward:-21.00 Loss:20.71 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.43 Step:824 CStep:440670\n",
            "Episode:510 Time:22:48:03 Reward:-21.00 Loss:32.20 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:33.33 Step:1244 CStep:441915\n",
            "Episode:511 Time:22:48:23 Reward:-21.00 Loss:19.58 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.54 Step:764 CStep:442680\n",
            "Episode:512 Time:22:48:44 Reward:-21.00 Loss:19.74 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.59 Step:764 CStep:443445\n",
            "Episode:513 Time:22:49:04 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:444210\n",
            "Episode:514 Time:22:49:28 Reward:-21.00 Loss:22.42 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.81 Step:884 CStep:445095\n",
            "Episode:515 Time:22:49:57 Reward:-21.00 Loss:27.41 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.41 Step:1064 CStep:446160\n",
            "Episode:516 Time:22:50:27 Reward:-21.00 Loss:28.88 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.11 Step:1124 CStep:447285\n",
            "Episode:517 Time:22:50:49 Reward:-21.00 Loss:20.50 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.97 Step:824 CStep:448110\n",
            "Episode:518 Time:22:51:09 Reward:-21.00 Loss:19.20 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.35 Step:764 CStep:448875\n",
            "Episode:519 Time:22:51:29 Reward:-21.00 Loss:19.71 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.40 Step:764 CStep:449640\n",
            "Episode:520 Time:22:51:50 Reward:-21.00 Loss:19.33 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.76 Step:764 CStep:450405\n",
            "Episode:521 Time:22:52:12 Reward:-21.00 Loss:20.66 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.98 Step:824 CStep:451230\n",
            "Episode:522 Time:22:52:37 Reward:-21.00 Loss:24.62 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.22 Step:944 CStep:452175\n",
            "Episode:523 Time:22:52:58 Reward:-21.00 Loss:19.08 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:452940\n",
            "Episode:524 Time:22:53:27 Reward:-21.00 Loss:26.31 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.90 Step:1064 CStep:454005\n",
            "Episode:525 Time:22:53:48 Reward:-21.00 Loss:19.44 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.60 Step:764 CStep:454770\n",
            "Episode:526 Time:22:54:10 Reward:-21.00 Loss:20.64 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.38 Step:824 CStep:455595\n",
            "Episode:527 Time:22:54:32 Reward:-21.00 Loss:20.86 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.14 Step:824 CStep:456420\n",
            "Episode:528 Time:22:54:53 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.35 Step:764 CStep:457185\n",
            "Episode:529 Time:22:55:15 Reward:-21.00 Loss:21.30 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.09 Step:824 CStep:458010\n",
            "Episode:530 Time:22:55:36 Reward:-21.00 Loss:19.77 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.98 Step:764 CStep:458775\n",
            "Episode:531 Time:22:55:58 Reward:-21.00 Loss:21.15 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.28 Step:824 CStep:459600\n",
            "Episode:532 Time:22:56:19 Reward:-21.00 Loss:19.65 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.68 Step:764 CStep:460365\n",
            "Episode:533 Time:22:56:41 Reward:-21.00 Loss:20.53 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.60 Step:824 CStep:461190\n",
            "Episode:534 Time:22:57:07 Reward:-21.00 Loss:24.21 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.80 Step:944 CStep:462135\n",
            "Episode:535 Time:22:57:36 Reward:-21.00 Loss:26.54 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.57 Step:1064 CStep:463200\n",
            "Episode:536 Time:22:58:00 Reward:-21.00 Loss:21.96 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.89 Step:884 CStep:464085\n",
            "Episode:537 Time:22:58:20 Reward:-21.00 Loss:19.44 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.37 Step:764 CStep:464850\n",
            "Episode:538 Time:22:58:42 Reward:-21.00 Loss:21.41 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.12 Step:824 CStep:465675\n",
            "Episode:539 Time:22:59:03 Reward:-21.00 Loss:18.62 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.95 Step:764 CStep:466440\n",
            "Episode:540 Time:22:59:24 Reward:-21.00 Loss:19.50 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.50 Step:764 CStep:467205\n",
            "Episode:541 Time:22:59:46 Reward:-21.00 Loss:21.16 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.61 Step:824 CStep:468030\n",
            "Episode:542 Time:23:00:15 Reward:-20.00 Loss:27.48 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.26 Step:1078 CStep:469109\n",
            "Episode:543 Time:23:00:40 Reward:-21.00 Loss:22.01 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.17 Step:884 CStep:469994\n",
            "Episode:544 Time:23:01:05 Reward:-21.00 Loss:22.98 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.14 Step:944 CStep:470939\n",
            "Episode:545 Time:23:01:32 Reward:-21.00 Loss:24.52 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.83 Step:1004 CStep:471944\n",
            "Episode:546 Time:23:01:52 Reward:-21.00 Loss:19.41 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.16 Step:764 CStep:472709\n",
            "Episode:547 Time:23:02:12 Reward:-21.00 Loss:18.62 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.69 Step:764 CStep:473474\n",
            "Episode:548 Time:23:02:37 Reward:-21.00 Loss:24.14 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.88 Step:944 CStep:474419\n",
            "Episode:549 Time:23:02:58 Reward:-21.00 Loss:18.53 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.32 Step:764 CStep:475184\n",
            "Episode:550 Time:23:03:19 Reward:-21.00 Loss:20.78 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.78 Step:824 CStep:476009\n",
            "Episode:551 Time:23:03:40 Reward:-21.00 Loss:18.99 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.82 Step:764 CStep:476774\n",
            "Episode:552 Time:23:04:04 Reward:-21.00 Loss:21.62 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.85 Step:884 CStep:477659\n",
            "Episode:553 Time:23:04:27 Reward:-21.00 Loss:20.31 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.55 Step:824 CStep:478484\n",
            "Episode:554 Time:23:04:57 Reward:-21.00 Loss:27.40 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.32 Step:1124 CStep:479609\n",
            "Episode:555 Time:23:05:18 Reward:-21.00 Loss:19.33 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.75 Step:764 CStep:480374\n",
            "Episode:556 Time:23:05:54 Reward:-20.00 Loss:32.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:36.14 Step:1341 CStep:481716\n",
            "Episode:557 Time:23:06:16 Reward:-21.00 Loss:20.81 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.31 Step:824 CStep:482541\n",
            "Episode:558 Time:23:06:37 Reward:-21.00 Loss:18.30 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.99 Step:764 CStep:483306\n",
            "Episode:559 Time:23:07:04 Reward:-21.00 Loss:25.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.45 Step:1004 CStep:484311\n",
            "Episode:560 Time:23:07:24 Reward:-21.00 Loss:18.06 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.34 Step:764 CStep:485076\n",
            "Episode:561 Time:23:07:45 Reward:-21.00 Loss:18.91 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.55 Step:764 CStep:485841\n",
            "Episode:562 Time:23:08:05 Reward:-21.00 Loss:17.92 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.65 Step:764 CStep:486606\n",
            "Episode:563 Time:23:08:31 Reward:-21.00 Loss:23.75 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.58 Step:944 CStep:487551\n",
            "Episode:564 Time:23:08:53 Reward:-21.00 Loss:20.39 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.39 Step:824 CStep:488376\n",
            "Episode:565 Time:23:09:15 Reward:-21.00 Loss:20.55 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.90 Step:824 CStep:489201\n",
            "Episode:566 Time:23:09:40 Reward:-21.00 Loss:23.22 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.94 Step:944 CStep:490146\n",
            "Episode:567 Time:23:10:05 Reward:-21.00 Loss:22.83 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.91 Step:944 CStep:491091\n",
            "Episode:568 Time:23:10:25 Reward:-21.00 Loss:18.71 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.19 Step:764 CStep:491856\n",
            "Episode:569 Time:23:10:47 Reward:-21.00 Loss:19.92 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.70 Step:824 CStep:492681\n",
            "Episode:570 Time:23:11:07 Reward:-21.00 Loss:18.97 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.63 Step:764 CStep:493446\n",
            "Episode:571 Time:23:11:32 Reward:-21.00 Loss:22.56 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.90 Step:944 CStep:494391\n",
            "Episode:572 Time:23:11:54 Reward:-21.00 Loss:19.89 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.80 Step:824 CStep:495216\n",
            "Episode:573 Time:23:12:16 Reward:-21.00 Loss:20.39 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.73 Step:824 CStep:496041\n",
            "Episode:574 Time:23:12:38 Reward:-21.00 Loss:20.24 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.15 Step:824 CStep:496866\n",
            "Episode:575 Time:23:12:58 Reward:-21.00 Loss:18.91 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.24 Step:764 CStep:497631\n",
            "Episode:576 Time:23:13:22 Reward:-21.00 Loss:21.83 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.25 Step:884 CStep:498516\n",
            "Episode:577 Time:23:13:45 Reward:-21.00 Loss:22.15 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.84 Step:884 CStep:499401\n",
            "Episode:578 Time:23:14:18 Reward:-21.00 Loss:30.33 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:32.89 Step:1246 CStep:500648\n",
            "Episode:579 Time:23:14:39 Reward:-21.00 Loss:18.66 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.35 Step:764 CStep:501413\n",
            "Episode:580 Time:23:14:59 Reward:-21.00 Loss:18.00 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.18 Step:764 CStep:502178\n",
            "Episode:581 Time:23:15:22 Reward:-21.00 Loss:21.52 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.46 Step:884 CStep:503063\n",
            "Episode:582 Time:23:15:44 Reward:-21.00 Loss:19.97 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.71 Step:824 CStep:503888\n",
            "Episode:583 Time:23:16:04 Reward:-21.00 Loss:19.41 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.07 Step:764 CStep:504653\n",
            "Episode:584 Time:23:16:24 Reward:-21.00 Loss:18.99 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.26 Step:764 CStep:505418\n",
            "Episode:585 Time:23:16:56 Reward:-21.00 Loss:29.03 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.31 Step:1184 CStep:506603\n",
            "Episode:586 Time:23:17:16 Reward:-21.00 Loss:18.54 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.19 Step:764 CStep:507368\n",
            "Episode:587 Time:23:17:41 Reward:-21.00 Loss:22.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.88 Step:944 CStep:508313\n",
            "Episode:588 Time:23:18:03 Reward:-21.00 Loss:20.02 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.83 Step:824 CStep:509138\n",
            "Episode:589 Time:23:18:23 Reward:-21.00 Loss:18.83 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.14 Step:764 CStep:509903\n",
            "Episode:590 Time:23:18:48 Reward:-21.00 Loss:23.37 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.84 Step:944 CStep:510848\n",
            "Episode:591 Time:23:19:09 Reward:-21.00 Loss:20.48 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.70 Step:824 CStep:511673\n",
            "Episode:592 Time:23:19:29 Reward:-21.00 Loss:18.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.15 Step:764 CStep:512438\n",
            "Episode:593 Time:23:19:49 Reward:-21.00 Loss:19.17 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.08 Step:764 CStep:513203\n",
            "Episode:594 Time:23:20:11 Reward:-21.00 Loss:20.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.71 Step:824 CStep:514028\n",
            "Episode:595 Time:23:20:32 Reward:-21.00 Loss:19.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.38 Step:764 CStep:514793\n",
            "Episode:596 Time:23:20:52 Reward:-21.00 Loss:18.51 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.15 Step:764 CStep:515558\n",
            "Episode:597 Time:23:21:12 Reward:-21.00 Loss:18.99 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.07 Step:764 CStep:516323\n",
            "Episode:598 Time:23:21:32 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.21 Step:764 CStep:517088\n",
            "Episode:599 Time:23:21:54 Reward:-21.00 Loss:20.86 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.74 Step:824 CStep:517913\n",
            "Episode:600 Time:23:22:15 Reward:-21.00 Loss:19.80 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.72 Step:824 CStep:518738\n",
            "Episode:601 Time:23:22:36 Reward:-21.00 Loss:19.03 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.21 Step:764 CStep:519503\n",
            "Episode:602 Time:23:22:57 Reward:-21.00 Loss:19.77 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.77 Step:824 CStep:520328\n",
            "Episode:603 Time:23:23:19 Reward:-21.00 Loss:19.87 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.78 Step:824 CStep:521153\n",
            "Episode:604 Time:23:23:39 Reward:-21.00 Loss:18.78 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.12 Step:764 CStep:521918\n",
            "Episode:605 Time:23:24:01 Reward:-21.00 Loss:20.66 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.77 Step:824 CStep:522743\n",
            "Episode:606 Time:23:24:21 Reward:-21.00 Loss:19.27 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.20 Step:764 CStep:523508\n",
            "Episode:607 Time:23:24:42 Reward:-21.00 Loss:19.30 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.26 Step:764 CStep:524273\n",
            "Episode:608 Time:23:25:11 Reward:-21.00 Loss:28.05 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.48 Step:1124 CStep:525398\n",
            "Episode:609 Time:23:25:35 Reward:-21.00 Loss:22.41 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.99 Step:912 CStep:526311\n",
            "Episode:610 Time:23:25:57 Reward:-21.00 Loss:20.58 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.58 Step:824 CStep:527136\n",
            "Episode:611 Time:23:26:27 Reward:-20.00 Loss:28.80 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.48 Step:1161 CStep:528298\n",
            "Episode:612 Time:23:26:49 Reward:-21.00 Loss:20.37 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.75 Step:824 CStep:529123\n",
            "Episode:613 Time:23:27:11 Reward:-21.00 Loss:20.65 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.72 Step:824 CStep:529948\n",
            "Episode:614 Time:23:27:34 Reward:-21.00 Loss:21.90 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.40 Step:884 CStep:530833\n",
            "Episode:615 Time:23:28:11 Reward:-20.00 Loss:34.49 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:37.53 Step:1401 CStep:532235\n",
            "Episode:616 Time:23:28:36 Reward:-21.00 Loss:22.06 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.06 Step:886 CStep:533122\n",
            "Episode:617 Time:23:28:57 Reward:-21.00 Loss:19.12 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.01 Step:764 CStep:533887\n",
            "Episode:618 Time:23:29:23 Reward:-21.00 Loss:22.58 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.98 Step:944 CStep:534832\n",
            "Episode:619 Time:23:29:43 Reward:-21.00 Loss:18.64 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.48 Step:764 CStep:535597\n",
            "Episode:620 Time:23:30:07 Reward:-21.00 Loss:22.12 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.61 Step:884 CStep:536482\n",
            "Episode:621 Time:23:30:27 Reward:-21.00 Loss:18.75 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.49 Step:764 CStep:537247\n",
            "Episode:622 Time:23:30:48 Reward:-21.00 Loss:18.81 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.37 Step:764 CStep:538012\n",
            "Episode:623 Time:23:31:08 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.26 Step:764 CStep:538777\n",
            "Episode:624 Time:23:31:31 Reward:-21.00 Loss:21.77 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.60 Step:884 CStep:539662\n",
            "Episode:625 Time:23:31:53 Reward:-21.00 Loss:19.84 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.02 Step:824 CStep:540487\n",
            "Episode:626 Time:23:32:14 Reward:-21.00 Loss:18.43 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.31 Step:764 CStep:541252\n",
            "Episode:627 Time:23:32:36 Reward:-21.00 Loss:19.80 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.11 Step:824 CStep:542077\n",
            "Episode:628 Time:23:32:58 Reward:-21.00 Loss:20.34 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.99 Step:824 CStep:542902\n",
            "Episode:629 Time:23:33:21 Reward:-21.00 Loss:22.16 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.56 Step:884 CStep:543787\n",
            "Episode:630 Time:23:33:45 Reward:-21.00 Loss:21.52 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.63 Step:884 CStep:544672\n",
            "Episode:631 Time:23:34:05 Reward:-21.00 Loss:19.02 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.38 Step:764 CStep:545437\n",
            "Episode:632 Time:23:34:30 Reward:-21.00 Loss:23.42 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.09 Step:944 CStep:546382\n",
            "Episode:633 Time:23:34:54 Reward:-21.00 Loss:21.79 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.66 Step:884 CStep:547267\n",
            "Episode:634 Time:23:35:17 Reward:-21.00 Loss:21.43 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.09 Step:854 CStep:548122\n",
            "Episode:635 Time:23:35:38 Reward:-21.00 Loss:18.40 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.56 Step:764 CStep:548887\n",
            "Episode:636 Time:23:36:01 Reward:-21.00 Loss:22.37 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.56 Step:884 CStep:549772\n",
            "Episode:637 Time:23:36:30 Reward:-21.00 Loss:25.39 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.28 Step:1064 CStep:550837\n",
            "Episode:638 Time:23:36:50 Reward:-21.00 Loss:18.91 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.21 Step:764 CStep:551602\n",
            "Episode:639 Time:23:37:12 Reward:-21.00 Loss:20.28 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.95 Step:824 CStep:552427\n",
            "Episode:640 Time:23:37:34 Reward:-21.00 Loss:20.35 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.11 Step:824 CStep:553252\n",
            "Episode:641 Time:23:37:56 Reward:-21.00 Loss:20.56 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.91 Step:824 CStep:554077\n",
            "Episode:642 Time:23:38:18 Reward:-21.00 Loss:20.29 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.97 Step:824 CStep:554902\n",
            "Episode:643 Time:23:38:38 Reward:-21.00 Loss:19.36 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:555667\n",
            "Episode:644 Time:23:39:00 Reward:-21.00 Loss:20.66 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.94 Step:824 CStep:556492\n",
            "Episode:645 Time:23:39:25 Reward:-21.00 Loss:23.40 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.10 Step:944 CStep:557437\n",
            "Episode:646 Time:23:39:47 Reward:-21.00 Loss:20.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.94 Step:824 CStep:558262\n",
            "Episode:647 Time:23:40:08 Reward:-21.00 Loss:18.71 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.42 Step:764 CStep:559027\n",
            "Episode:648 Time:23:40:28 Reward:-21.00 Loss:18.88 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.39 Step:764 CStep:559792\n",
            "Episode:649 Time:23:40:49 Reward:-21.00 Loss:18.93 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.50 Step:764 CStep:560557\n",
            "Episode:650 Time:23:41:10 Reward:-21.00 Loss:20.19 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.89 Step:824 CStep:561382\n",
            "Episode:651 Time:23:41:34 Reward:-21.00 Loss:21.70 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.61 Step:884 CStep:562267\n",
            "Episode:652 Time:23:41:54 Reward:-21.00 Loss:19.68 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.33 Step:764 CStep:563032\n",
            "Episode:653 Time:23:42:16 Reward:-21.00 Loss:20.86 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.98 Step:824 CStep:563857\n",
            "Episode:654 Time:23:42:38 Reward:-21.00 Loss:21.17 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.15 Step:824 CStep:564682\n",
            "Episode:655 Time:23:43:01 Reward:-20.00 Loss:21.41 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.56 Step:842 CStep:565525\n",
            "Episode:656 Time:23:43:24 Reward:-21.00 Loss:21.89 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.43 Step:884 CStep:566410\n",
            "Episode:657 Time:23:43:46 Reward:-21.00 Loss:20.47 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.02 Step:824 CStep:567235\n",
            "Episode:658 Time:23:44:07 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.39 Step:764 CStep:568000\n",
            "Episode:659 Time:23:44:30 Reward:-21.00 Loss:22.52 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.38 Step:884 CStep:568885\n",
            "Episode:660 Time:23:44:52 Reward:-21.00 Loss:21.30 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.05 Step:824 CStep:569710\n",
            "Episode:661 Time:23:45:14 Reward:-21.00 Loss:21.14 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.88 Step:824 CStep:570535\n",
            "Episode:662 Time:23:45:36 Reward:-21.00 Loss:20.91 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.06 Step:824 CStep:571360\n",
            "Episode:663 Time:23:45:58 Reward:-21.00 Loss:20.55 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.00 Step:824 CStep:572185\n",
            "Episode:664 Time:23:46:19 Reward:-21.00 Loss:19.49 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.45 Step:764 CStep:572950\n",
            "Episode:665 Time:23:46:40 Reward:-21.00 Loss:18.44 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.81 Step:764 CStep:573715\n",
            "Episode:666 Time:23:47:02 Reward:-21.00 Loss:20.70 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.28 Step:824 CStep:574540\n",
            "Episode:667 Time:23:47:26 Reward:-21.00 Loss:21.51 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.07 Step:884 CStep:575425\n",
            "Episode:668 Time:23:47:48 Reward:-21.00 Loss:20.95 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.31 Step:824 CStep:576250\n",
            "Episode:669 Time:23:48:09 Reward:-21.00 Loss:19.28 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.00 Step:764 CStep:577015\n",
            "Episode:670 Time:23:48:32 Reward:-21.00 Loss:20.26 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.97 Step:824 CStep:577840\n",
            "Episode:671 Time:23:48:55 Reward:-21.00 Loss:20.87 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.35 Step:824 CStep:578665\n",
            "Episode:672 Time:23:49:17 Reward:-21.00 Loss:21.02 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.14 Step:824 CStep:579490\n",
            "Episode:673 Time:23:49:39 Reward:-21.00 Loss:20.41 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.23 Step:826 CStep:580317\n",
            "Episode:674 Time:23:50:00 Reward:-21.00 Loss:19.26 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.89 Step:764 CStep:581082\n",
            "Episode:675 Time:23:50:28 Reward:-21.00 Loss:24.70 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.00 Step:1004 CStep:582087\n",
            "Episode:676 Time:23:50:53 Reward:-21.00 Loss:22.25 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.83 Step:884 CStep:582972\n",
            "Episode:677 Time:23:51:16 Reward:-21.00 Loss:21.05 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.99 Step:824 CStep:583797\n",
            "Episode:678 Time:23:51:37 Reward:-21.00 Loss:20.02 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.96 Step:764 CStep:584562\n",
            "Episode:679 Time:23:51:58 Reward:-21.00 Loss:19.79 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.05 Step:764 CStep:585327\n",
            "Episode:680 Time:23:52:23 Reward:-21.00 Loss:23.70 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.63 Step:944 CStep:586272\n",
            "Episode:681 Time:23:52:44 Reward:-21.00 Loss:19.05 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.64 Step:764 CStep:587037\n",
            "Episode:682 Time:23:53:05 Reward:-21.00 Loss:19.84 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.77 Step:764 CStep:587802\n",
            "Episode:683 Time:23:53:27 Reward:-21.00 Loss:20.95 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.28 Step:824 CStep:588627\n",
            "Episode:684 Time:23:53:59 Reward:-21.00 Loss:29.88 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.83 Step:1184 CStep:589812\n",
            "Episode:685 Time:23:54:23 Reward:-21.00 Loss:22.07 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.00 Step:886 CStep:590699\n",
            "Episode:686 Time:23:54:47 Reward:-21.00 Loss:22.06 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.07 Step:884 CStep:591584\n",
            "Episode:687 Time:23:55:08 Reward:-21.00 Loss:18.93 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.73 Step:764 CStep:592349\n",
            "Episode:688 Time:23:55:34 Reward:-21.00 Loss:23.65 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.95 Step:944 CStep:593294\n",
            "Episode:689 Time:23:55:54 Reward:-21.00 Loss:19.11 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.85 Step:764 CStep:594059\n",
            "Episode:690 Time:23:56:15 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.84 Step:764 CStep:594824\n",
            "Episode:691 Time:23:56:38 Reward:-21.00 Loss:20.89 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.41 Step:824 CStep:595649\n",
            "Episode:692 Time:23:57:00 Reward:-21.00 Loss:20.71 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.17 Step:824 CStep:596474\n",
            "Episode:693 Time:23:57:29 Reward:-21.00 Loss:26.55 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.84 Step:1064 CStep:597539\n",
            "Episode:694 Time:23:57:51 Reward:-21.00 Loss:21.07 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.35 Step:824 CStep:598364\n",
            "Episode:695 Time:23:58:13 Reward:-21.00 Loss:21.30 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.34 Step:824 CStep:599189\n",
            "Episode:696 Time:23:58:36 Reward:-21.00 Loss:20.79 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.38 Step:824 CStep:600014\n",
            "Episode:697 Time:23:58:57 Reward:-21.00 Loss:18.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.21 Step:764 CStep:600779\n",
            "Episode:698 Time:23:59:26 Reward:-21.00 Loss:26.02 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.63 Step:1032 CStep:601812\n",
            "Episode:699 Time:23:59:49 Reward:-21.00 Loss:19.84 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.96 Step:824 CStep:602637\n",
            "Episode:700 Time:00:00:12 Reward:-21.00 Loss:21.34 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.53 Step:852 CStep:603490\n",
            "Episode:701 Time:00:00:36 Reward:-21.00 Loss:22.23 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.35 Step:884 CStep:604375\n",
            "Episode:702 Time:00:00:58 Reward:-21.00 Loss:18.97 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.12 Step:764 CStep:605140\n",
            "Episode:703 Time:00:01:28 Reward:-21.00 Loss:28.84 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.61 Step:1124 CStep:606265\n",
            "Episode:704 Time:00:01:49 Reward:-21.00 Loss:18.89 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.57 Step:764 CStep:607030\n",
            "Episode:705 Time:00:02:09 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.65 Step:764 CStep:607795\n",
            "Episode:706 Time:00:02:30 Reward:-21.00 Loss:18.38 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.55 Step:764 CStep:608560\n",
            "Episode:707 Time:00:02:57 Reward:-21.00 Loss:25.29 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.53 Step:1004 CStep:609565\n",
            "Episode:708 Time:00:03:22 Reward:-21.00 Loss:21.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.10 Step:884 CStep:610450\n",
            "Episode:709 Time:00:03:42 Reward:-21.00 Loss:19.47 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.59 Step:764 CStep:611215\n",
            "Episode:710 Time:00:04:09 Reward:-21.00 Loss:24.97 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.15 Step:1004 CStep:612220\n",
            "Episode:711 Time:00:04:32 Reward:-21.00 Loss:19.89 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.37 Step:824 CStep:613045\n",
            "Episode:712 Time:00:04:56 Reward:-21.00 Loss:21.42 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.19 Step:885 CStep:613931\n",
            "Episode:713 Time:00:05:32 Reward:-21.00 Loss:32.29 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:35.76 Step:1334 CStep:615266\n",
            "Episode:714 Time:00:05:56 Reward:-20.00 Loss:22.27 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.08 Step:902 CStep:616169\n",
            "Episode:715 Time:00:06:16 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.67 Step:764 CStep:616934\n",
            "Episode:716 Time:00:06:42 Reward:-21.00 Loss:24.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.70 Step:944 CStep:617879\n",
            "Episode:717 Time:00:07:05 Reward:-21.00 Loss:19.75 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.74 Step:824 CStep:618704\n",
            "Episode:718 Time:00:07:26 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.82 Step:764 CStep:619469\n",
            "Episode:719 Time:00:07:51 Reward:-21.00 Loss:22.42 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.85 Step:945 CStep:620415\n",
            "Episode:720 Time:00:08:14 Reward:-21.00 Loss:19.95 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.32 Step:824 CStep:621240\n",
            "Episode:721 Time:00:08:36 Reward:-21.00 Loss:20.11 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.29 Step:824 CStep:622065\n",
            "Episode:722 Time:00:08:58 Reward:-21.00 Loss:20.33 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.23 Step:824 CStep:622890\n",
            "Episode:723 Time:00:09:27 Reward:-21.00 Loss:25.78 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.80 Step:1064 CStep:623955\n",
            "Episode:724 Time:00:09:53 Reward:-21.00 Loss:22.40 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.60 Step:944 CStep:624900\n",
            "Episode:725 Time:00:10:20 Reward:-21.00 Loss:24.35 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.13 Step:1004 CStep:625905\n",
            "Episode:726 Time:00:10:41 Reward:-21.00 Loss:18.06 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.73 Step:764 CStep:626670\n",
            "Episode:727 Time:00:11:01 Reward:-21.00 Loss:18.83 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.70 Step:764 CStep:627435\n",
            "Episode:728 Time:00:11:25 Reward:-21.00 Loss:21.12 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.90 Step:884 CStep:628320\n",
            "Episode:729 Time:00:11:51 Reward:-21.00 Loss:22.37 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.45 Step:944 CStep:629265\n",
            "Episode:730 Time:00:12:16 Reward:-21.00 Loss:22.32 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.45 Step:944 CStep:630210\n",
            "Episode:731 Time:00:12:48 Reward:-21.00 Loss:27.65 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:32.02 Step:1184 CStep:631395\n",
            "Episode:732 Time:00:13:20 Reward:-21.00 Loss:28.16 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:32.30 Step:1186 CStep:632582\n",
            "Episode:733 Time:00:13:42 Reward:-21.00 Loss:18.22 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.22 Step:764 CStep:633347\n",
            "Episode:734 Time:00:14:03 Reward:-21.00 Loss:18.65 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.49 Step:792 CStep:634140\n",
            "Episode:735 Time:00:14:24 Reward:-21.00 Loss:18.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.86 Step:764 CStep:634905\n",
            "Episode:736 Time:00:14:45 Reward:-21.00 Loss:17.93 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.83 Step:764 CStep:635670\n",
            "Episode:737 Time:00:15:09 Reward:-21.00 Loss:20.88 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.25 Step:884 CStep:636555\n",
            "Episode:738 Time:00:15:30 Reward:-21.00 Loss:18.13 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.93 Step:764 CStep:637320\n",
            "Episode:739 Time:00:15:54 Reward:-21.00 Loss:20.68 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.29 Step:884 CStep:638205\n",
            "Episode:740 Time:00:16:19 Reward:-21.00 Loss:20.73 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.31 Step:884 CStep:639090\n",
            "Episode:741 Time:00:16:41 Reward:-21.00 Loss:19.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.58 Step:824 CStep:639915\n",
            "Episode:742 Time:00:17:02 Reward:-21.00 Loss:18.58 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.09 Step:764 CStep:640680\n",
            "Episode:743 Time:00:17:31 Reward:-21.00 Loss:26.18 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.03 Step:1064 CStep:641745\n",
            "Episode:744 Time:00:17:54 Reward:-21.00 Loss:19.90 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.48 Step:824 CStep:642570\n",
            "Episode:745 Time:00:18:19 Reward:-21.00 Loss:22.62 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.47 Step:944 CStep:643515\n",
            "Episode:746 Time:00:18:42 Reward:-21.00 Loss:19.77 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.28 Step:824 CStep:644340\n",
            "Episode:747 Time:00:19:04 Reward:-21.00 Loss:19.31 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.19 Step:824 CStep:645165\n",
            "Episode:748 Time:00:19:24 Reward:-21.00 Loss:18.46 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.71 Step:764 CStep:645930\n",
            "Episode:749 Time:00:19:47 Reward:-21.00 Loss:18.78 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.25 Step:824 CStep:646755\n",
            "Episode:750 Time:00:20:11 Reward:-21.00 Loss:20.77 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.87 Step:884 CStep:647640\n",
            "Episode:751 Time:00:20:31 Reward:-21.00 Loss:18.61 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.70 Step:764 CStep:648405\n",
            "Episode:752 Time:00:20:52 Reward:-21.00 Loss:18.05 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.62 Step:764 CStep:649170\n",
            "Episode:753 Time:00:21:21 Reward:-21.00 Loss:25.55 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.60 Step:1064 CStep:650235\n",
            "Episode:754 Time:00:21:44 Reward:-21.00 Loss:21.68 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.88 Step:884 CStep:651120\n",
            "Episode:755 Time:00:22:05 Reward:-21.00 Loss:18.44 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.77 Step:764 CStep:651885\n",
            "Episode:756 Time:00:22:31 Reward:-21.00 Loss:23.37 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.41 Step:944 CStep:652830\n",
            "Episode:757 Time:00:22:57 Reward:-20.00 Loss:23.36 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.43 Step:980 CStep:653811\n",
            "Episode:758 Time:00:23:18 Reward:-21.00 Loss:18.34 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.75 Step:764 CStep:654576\n",
            "Episode:759 Time:00:23:38 Reward:-21.00 Loss:18.66 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.47 Step:764 CStep:655341\n",
            "Episode:760 Time:00:23:59 Reward:-21.00 Loss:18.18 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.59 Step:764 CStep:656106\n",
            "Episode:761 Time:00:24:25 Reward:-21.00 Loss:22.65 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.76 Step:944 CStep:657051\n",
            "Episode:762 Time:00:24:45 Reward:-21.00 Loss:18.30 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.72 Step:764 CStep:657816\n",
            "Episode:763 Time:00:25:11 Reward:-21.00 Loss:22.30 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.55 Step:944 CStep:658761\n",
            "Episode:764 Time:00:25:31 Reward:-21.00 Loss:18.09 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.51 Step:764 CStep:659526\n",
            "Episode:765 Time:00:25:54 Reward:-21.00 Loss:19.72 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.23 Step:824 CStep:660351\n",
            "Episode:766 Time:00:26:24 Reward:-21.00 Loss:27.68 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.16 Step:1124 CStep:661476\n",
            "Episode:767 Time:00:26:44 Reward:-21.00 Loss:18.77 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:662241\n",
            "Episode:768 Time:00:27:06 Reward:-21.00 Loss:19.91 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.19 Step:824 CStep:663066\n",
            "Episode:769 Time:00:27:27 Reward:-21.00 Loss:19.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.51 Step:764 CStep:663831\n",
            "Episode:770 Time:00:27:55 Reward:-21.00 Loss:25.66 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.44 Step:1065 CStep:664897\n",
            "Episode:771 Time:00:28:20 Reward:-21.00 Loss:23.23 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.02 Step:944 CStep:665842\n",
            "Episode:772 Time:00:28:41 Reward:-21.00 Loss:18.04 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.31 Step:764 CStep:666607\n",
            "Episode:773 Time:00:29:01 Reward:-21.00 Loss:18.34 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:667372\n",
            "Episode:774 Time:00:29:23 Reward:-21.00 Loss:20.03 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.96 Step:824 CStep:668197\n",
            "Episode:775 Time:00:29:44 Reward:-21.00 Loss:18.52 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.53 Step:764 CStep:668962\n",
            "Episode:776 Time:00:30:07 Reward:-21.00 Loss:21.80 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.56 Step:884 CStep:669847\n",
            "Episode:777 Time:00:30:29 Reward:-21.00 Loss:19.96 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.95 Step:824 CStep:670672\n",
            "Episode:778 Time:00:30:51 Reward:-21.00 Loss:19.12 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.02 Step:824 CStep:671497\n",
            "Episode:779 Time:00:31:15 Reward:-21.00 Loss:21.91 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.66 Step:884 CStep:672382\n",
            "Episode:780 Time:00:31:35 Reward:-21.00 Loss:19.30 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.38 Step:764 CStep:673147\n",
            "Episode:781 Time:00:31:56 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.45 Step:764 CStep:673912\n",
            "Episode:782 Time:00:32:16 Reward:-21.00 Loss:18.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.52 Step:764 CStep:674677\n",
            "Episode:783 Time:00:32:37 Reward:-21.00 Loss:18.63 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.43 Step:764 CStep:675442\n",
            "Episode:784 Time:00:32:57 Reward:-21.00 Loss:19.63 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.35 Step:764 CStep:676207\n",
            "Episode:785 Time:00:33:17 Reward:-21.00 Loss:18.60 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.36 Step:764 CStep:676972\n",
            "Episode:786 Time:00:33:38 Reward:-21.00 Loss:19.25 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.45 Step:764 CStep:677737\n",
            "Episode:787 Time:00:34:01 Reward:-21.00 Loss:21.98 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.61 Step:884 CStep:678622\n",
            "Episode:788 Time:00:34:28 Reward:-21.00 Loss:24.82 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.83 Step:1004 CStep:679627\n",
            "Episode:789 Time:00:34:49 Reward:-21.00 Loss:19.23 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.55 Step:764 CStep:680392\n",
            "Episode:790 Time:00:35:09 Reward:-21.00 Loss:18.97 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.62 Step:764 CStep:681157\n",
            "Episode:791 Time:00:35:30 Reward:-21.00 Loss:18.94 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.43 Step:764 CStep:681922\n",
            "Episode:792 Time:00:35:50 Reward:-21.00 Loss:19.01 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.46 Step:764 CStep:682687\n",
            "Episode:793 Time:00:36:11 Reward:-21.00 Loss:19.37 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.42 Step:764 CStep:683452\n",
            "Episode:794 Time:00:36:34 Reward:-21.00 Loss:22.20 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.66 Step:884 CStep:684337\n",
            "Episode:795 Time:00:36:56 Reward:-21.00 Loss:20.28 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.93 Step:824 CStep:685162\n",
            "Episode:796 Time:00:37:17 Reward:-21.00 Loss:19.54 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.35 Step:764 CStep:685927\n",
            "Episode:797 Time:00:37:37 Reward:-21.00 Loss:19.43 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.48 Step:764 CStep:686692\n",
            "Episode:798 Time:00:37:58 Reward:-21.00 Loss:19.29 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.51 Step:764 CStep:687457\n",
            "Episode:799 Time:00:38:18 Reward:-21.00 Loss:18.96 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.57 Step:764 CStep:688222\n",
            "Episode:800 Time:00:38:50 Reward:-21.00 Loss:29.36 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.58 Step:1184 CStep:689407\n",
            "Episode:801 Time:00:39:13 Reward:-21.00 Loss:22.25 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.68 Step:884 CStep:690292\n",
            "Episode:802 Time:00:39:36 Reward:-21.00 Loss:20.53 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.13 Step:824 CStep:691117\n",
            "Episode:803 Time:00:40:07 Reward:-21.00 Loss:29.45 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.65 Step:1184 CStep:692302\n",
            "Episode:804 Time:00:40:33 Reward:-21.00 Loss:23.19 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.71 Step:944 CStep:693247\n",
            "Episode:805 Time:00:40:54 Reward:-21.00 Loss:18.96 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.67 Step:764 CStep:694012\n",
            "Episode:806 Time:00:41:14 Reward:-21.00 Loss:18.84 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.85 Step:764 CStep:694777\n",
            "Episode:807 Time:00:41:35 Reward:-21.00 Loss:18.69 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.71 Step:764 CStep:695542\n",
            "Episode:808 Time:00:41:58 Reward:-21.00 Loss:19.99 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.48 Step:824 CStep:696367\n",
            "Episode:809 Time:00:42:20 Reward:-21.00 Loss:21.12 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.49 Step:824 CStep:697192\n",
            "Episode:810 Time:00:42:45 Reward:-21.00 Loss:24.48 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.26 Step:944 CStep:698137\n",
            "Episode:811 Time:00:43:08 Reward:-21.00 Loss:20.73 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.17 Step:824 CStep:698962\n",
            "Episode:812 Time:00:43:30 Reward:-21.00 Loss:20.84 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.08 Step:824 CStep:699787\n",
            "Episode:813 Time:00:43:52 Reward:-21.00 Loss:20.34 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.99 Step:824 CStep:700612\n",
            "Episode:814 Time:00:44:20 Reward:-21.00 Loss:26.49 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:28.35 Step:1064 CStep:701677\n",
            "Episode:815 Time:00:44:44 Reward:-21.00 Loss:22.16 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.09 Step:884 CStep:702562\n",
            "Episode:816 Time:00:45:05 Reward:-21.00 Loss:19.40 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.59 Step:764 CStep:703327\n",
            "Episode:817 Time:00:45:29 Reward:-21.00 Loss:22.26 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.89 Step:884 CStep:704212\n",
            "Episode:818 Time:00:45:53 Reward:-21.00 Loss:22.08 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.49 Step:912 CStep:705125\n",
            "Episode:819 Time:00:46:17 Reward:-21.00 Loss:21.77 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.79 Step:884 CStep:706010\n",
            "Episode:820 Time:00:46:41 Reward:-21.00 Loss:22.08 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.65 Step:884 CStep:706895\n",
            "Episode:821 Time:00:47:03 Reward:-21.00 Loss:20.47 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.09 Step:824 CStep:707720\n",
            "Episode:822 Time:00:47:23 Reward:-21.00 Loss:18.79 Last_100_Avg_Rew:-20.990 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.56 Step:764 CStep:708485\n",
            "Episode:823 Time:00:47:49 Reward:-20.00 Loss:24.51 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.17 Step:979 CStep:709465\n",
            "Episode:824 Time:00:48:10 Reward:-21.00 Loss:18.66 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.52 Step:764 CStep:710230\n",
            "Episode:825 Time:00:48:30 Reward:-21.00 Loss:18.49 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.31 Step:764 CStep:710995\n",
            "Episode:826 Time:00:48:51 Reward:-21.00 Loss:19.38 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.37 Step:764 CStep:711760\n",
            "Episode:827 Time:00:49:11 Reward:-21.00 Loss:19.43 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.26 Step:764 CStep:712525\n",
            "Episode:828 Time:00:49:33 Reward:-20.00 Loss:21.22 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.36 Step:842 CStep:713368\n",
            "Episode:829 Time:00:49:57 Reward:-21.00 Loss:22.34 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.60 Step:884 CStep:714253\n",
            "Episode:830 Time:00:50:17 Reward:-21.00 Loss:19.69 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.46 Step:764 CStep:715018\n",
            "Episode:831 Time:00:50:38 Reward:-21.00 Loss:18.98 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.38 Step:764 CStep:715783\n",
            "Episode:832 Time:00:51:09 Reward:-21.00 Loss:30.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.56 Step:1184 CStep:716968\n",
            "Episode:833 Time:00:51:30 Reward:-21.00 Loss:18.86 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.48 Step:764 CStep:717733\n",
            "Episode:834 Time:00:51:50 Reward:-21.00 Loss:19.21 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.39 Step:764 CStep:718498\n",
            "Episode:835 Time:00:52:10 Reward:-21.00 Loss:19.31 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.29 Step:764 CStep:719263\n",
            "Episode:836 Time:00:52:44 Reward:-21.00 Loss:31.64 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:33.51 Step:1244 CStep:720508\n",
            "Episode:837 Time:00:53:14 Reward:-21.00 Loss:26.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.75 Step:1092 CStep:721601\n",
            "Episode:838 Time:00:53:34 Reward:-21.00 Loss:18.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.71 Step:764 CStep:722366\n",
            "Episode:839 Time:00:53:58 Reward:-21.00 Loss:22.16 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.90 Step:884 CStep:723251\n",
            "Episode:840 Time:00:54:22 Reward:-21.00 Loss:21.05 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.68 Step:872 CStep:724124\n",
            "Episode:841 Time:00:54:43 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.68 Step:764 CStep:724889\n",
            "Episode:842 Time:00:55:07 Reward:-21.00 Loss:22.31 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.96 Step:884 CStep:725774\n",
            "Episode:843 Time:00:55:42 Reward:-21.00 Loss:31.62 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:35.38 Step:1308 CStep:727083\n",
            "Episode:844 Time:00:56:07 Reward:-21.00 Loss:23.10 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.32 Step:944 CStep:728028\n",
            "Episode:845 Time:00:56:29 Reward:-21.00 Loss:20.05 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.79 Step:824 CStep:728853\n",
            "Episode:846 Time:00:56:51 Reward:-21.00 Loss:19.57 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.91 Step:824 CStep:729678\n",
            "Episode:847 Time:00:57:11 Reward:-21.00 Loss:18.12 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.25 Step:764 CStep:730443\n",
            "Episode:848 Time:00:57:38 Reward:-21.00 Loss:24.52 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.53 Step:1004 CStep:731448\n",
            "Episode:849 Time:00:57:58 Reward:-21.00 Loss:18.41 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.24 Step:764 CStep:732213\n",
            "Episode:850 Time:00:58:25 Reward:-21.00 Loss:24.48 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.65 Step:1004 CStep:733218\n",
            "Episode:851 Time:00:58:49 Reward:-21.00 Loss:22.09 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.47 Step:912 CStep:734131\n",
            "Episode:852 Time:00:59:10 Reward:-21.00 Loss:18.46 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.11 Step:764 CStep:734896\n",
            "Episode:853 Time:00:59:33 Reward:-21.00 Loss:20.00 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.12 Step:824 CStep:735721\n",
            "Episode:854 Time:00:59:57 Reward:-21.00 Loss:20.64 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.01 Step:884 CStep:736606\n",
            "Episode:855 Time:01:00:21 Reward:-21.00 Loss:21.38 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.61 Step:884 CStep:737491\n",
            "Episode:856 Time:01:00:43 Reward:-21.00 Loss:19.88 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.12 Step:824 CStep:738316\n",
            "Episode:857 Time:01:01:04 Reward:-21.00 Loss:18.60 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.40 Step:764 CStep:739081\n",
            "Episode:858 Time:01:01:24 Reward:-21.00 Loss:18.10 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.50 Step:764 CStep:739846\n",
            "Episode:859 Time:01:01:48 Reward:-21.00 Loss:21.52 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.63 Step:884 CStep:740731\n",
            "Episode:860 Time:01:02:10 Reward:-21.00 Loss:19.80 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.97 Step:824 CStep:741556\n",
            "Episode:861 Time:01:02:33 Reward:-21.00 Loss:21.83 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.58 Step:884 CStep:742441\n",
            "Episode:862 Time:01:02:54 Reward:-21.00 Loss:18.33 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.43 Step:764 CStep:743206\n",
            "Episode:863 Time:01:03:19 Reward:-21.00 Loss:23.48 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.29 Step:944 CStep:744151\n",
            "Episode:864 Time:01:03:41 Reward:-21.00 Loss:20.23 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.22 Step:825 CStep:744977\n",
            "Episode:865 Time:01:04:02 Reward:-21.00 Loss:18.95 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.91 Step:764 CStep:745742\n",
            "Episode:866 Time:01:04:27 Reward:-21.00 Loss:21.12 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.45 Step:884 CStep:746627\n",
            "Episode:867 Time:01:04:51 Reward:-21.00 Loss:21.60 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.34 Step:884 CStep:747512\n",
            "Episode:868 Time:01:05:12 Reward:-21.00 Loss:19.21 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.06 Step:764 CStep:748277\n",
            "Episode:869 Time:01:05:34 Reward:-21.00 Loss:19.68 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.30 Step:824 CStep:749102\n",
            "Episode:870 Time:01:05:55 Reward:-21.00 Loss:18.58 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.62 Step:764 CStep:749867\n",
            "Episode:871 Time:01:06:15 Reward:-21.00 Loss:18.88 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.37 Step:764 CStep:750632\n",
            "Episode:872 Time:01:06:41 Reward:-21.00 Loss:22.49 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.35 Step:944 CStep:751577\n",
            "Episode:873 Time:01:07:01 Reward:-21.00 Loss:19.06 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.43 Step:764 CStep:752342\n",
            "Episode:874 Time:01:07:22 Reward:-21.00 Loss:18.80 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.63 Step:764 CStep:753107\n",
            "Episode:875 Time:01:07:42 Reward:-21.00 Loss:18.52 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.63 Step:764 CStep:753872\n",
            "Episode:876 Time:01:08:05 Reward:-21.00 Loss:20.24 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.30 Step:824 CStep:754697\n",
            "Episode:877 Time:01:08:25 Reward:-21.00 Loss:18.43 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.68 Step:764 CStep:755462\n",
            "Episode:878 Time:01:08:46 Reward:-21.00 Loss:18.27 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.52 Step:764 CStep:756227\n",
            "Episode:879 Time:01:09:07 Reward:-21.00 Loss:18.66 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.77 Step:764 CStep:756992\n",
            "Episode:880 Time:01:09:29 Reward:-21.00 Loss:21.17 Last_100_Avg_Rew:-20.980 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.47 Step:824 CStep:757817\n",
            "Episode:881 Time:01:09:54 Reward:-20.00 Loss:22.63 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.96 Step:919 CStep:758737\n",
            "Episode:882 Time:01:10:16 Reward:-21.00 Loss:20.72 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.32 Step:824 CStep:759562\n",
            "Episode:883 Time:01:10:40 Reward:-21.00 Loss:21.84 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.89 Step:884 CStep:760447\n",
            "Episode:884 Time:01:11:01 Reward:-21.00 Loss:18.27 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.61 Step:764 CStep:761212\n",
            "Episode:885 Time:01:11:28 Reward:-19.00 Loss:24.73 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.13 Step:1014 CStep:762227\n",
            "Episode:886 Time:01:11:50 Reward:-21.00 Loss:20.85 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.38 Step:824 CStep:763052\n",
            "Episode:887 Time:01:12:15 Reward:-21.00 Loss:22.23 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.64 Step:912 CStep:763965\n",
            "Episode:888 Time:01:12:35 Reward:-21.00 Loss:18.43 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.48 Step:764 CStep:764730\n",
            "Episode:889 Time:01:12:58 Reward:-21.00 Loss:19.88 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.15 Step:824 CStep:765555\n",
            "Episode:890 Time:01:13:24 Reward:-21.00 Loss:23.70 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:26.26 Step:972 CStep:766528\n",
            "Episode:891 Time:01:13:44 Reward:-21.00 Loss:18.55 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.56 Step:764 CStep:767293\n",
            "Episode:892 Time:01:14:12 Reward:-21.00 Loss:24.73 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.12 Step:1004 CStep:768298\n",
            "Episode:893 Time:01:14:32 Reward:-21.00 Loss:18.05 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.46 Step:764 CStep:769063\n",
            "Episode:894 Time:01:15:04 Reward:-21.00 Loss:28.27 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:32.18 Step:1184 CStep:770248\n",
            "Episode:895 Time:01:15:25 Reward:-21.00 Loss:18.23 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.80 Step:764 CStep:771013\n",
            "Episode:896 Time:01:15:47 Reward:-21.00 Loss:20.52 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.16 Step:824 CStep:771838\n",
            "Episode:897 Time:01:16:08 Reward:-21.00 Loss:18.90 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.75 Step:764 CStep:772603\n",
            "Episode:898 Time:01:16:28 Reward:-21.00 Loss:18.91 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.53 Step:764 CStep:773368\n",
            "Episode:899 Time:01:16:49 Reward:-21.00 Loss:19.50 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.90 Step:764 CStep:774133\n",
            "Episode:900 Time:01:17:13 Reward:-21.00 Loss:22.30 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.11 Step:884 CStep:775018\n",
            "Episode:901 Time:01:17:34 Reward:-21.00 Loss:18.94 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.79 Step:764 CStep:775783\n",
            "Episode:902 Time:01:17:55 Reward:-21.00 Loss:19.46 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.42 Step:764 CStep:776548\n",
            "Episode:903 Time:01:18:17 Reward:-21.00 Loss:20.80 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.97 Step:824 CStep:777373\n",
            "Episode:904 Time:01:18:37 Reward:-21.00 Loss:19.23 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.29 Step:764 CStep:778138\n",
            "Episode:905 Time:01:19:01 Reward:-21.00 Loss:22.91 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.71 Step:884 CStep:779023\n",
            "Episode:906 Time:01:19:24 Reward:-21.00 Loss:22.67 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.58 Step:884 CStep:779908\n",
            "Episode:907 Time:01:19:45 Reward:-21.00 Loss:19.15 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.37 Step:764 CStep:780673\n",
            "Episode:908 Time:01:20:05 Reward:-21.00 Loss:18.88 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.47 Step:764 CStep:781438\n",
            "Episode:909 Time:01:20:27 Reward:-21.00 Loss:20.92 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.27 Step:824 CStep:782263\n",
            "Episode:910 Time:01:20:48 Reward:-21.00 Loss:19.31 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.54 Step:764 CStep:783028\n",
            "Episode:911 Time:01:21:09 Reward:-21.00 Loss:19.18 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.65 Step:764 CStep:783793\n",
            "Episode:912 Time:01:21:31 Reward:-21.00 Loss:20.71 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.12 Step:824 CStep:784618\n",
            "Episode:913 Time:01:21:51 Reward:-21.00 Loss:19.22 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.53 Step:764 CStep:785383\n",
            "Episode:914 Time:01:22:12 Reward:-21.00 Loss:19.22 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.69 Step:764 CStep:786148\n",
            "Episode:915 Time:01:22:32 Reward:-21.00 Loss:19.53 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.51 Step:764 CStep:786913\n",
            "Episode:916 Time:01:22:53 Reward:-21.00 Loss:19.26 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.55 Step:764 CStep:787678\n",
            "Episode:917 Time:01:23:13 Reward:-21.00 Loss:19.74 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.55 Step:764 CStep:788443\n",
            "Episode:918 Time:01:23:37 Reward:-21.00 Loss:22.70 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.46 Step:884 CStep:789328\n",
            "Episode:919 Time:01:23:57 Reward:-21.00 Loss:20.12 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.50 Step:764 CStep:790093\n",
            "Episode:920 Time:01:24:18 Reward:-21.00 Loss:19.23 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.62 Step:764 CStep:790858\n",
            "Episode:921 Time:01:24:40 Reward:-21.00 Loss:20.93 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.15 Step:824 CStep:791683\n",
            "Episode:922 Time:01:25:01 Reward:-21.00 Loss:18.68 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.66 Step:764 CStep:792448\n",
            "Episode:923 Time:01:25:22 Reward:-21.00 Loss:20.23 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.57 Step:792 CStep:793241\n",
            "Episode:924 Time:01:25:43 Reward:-21.00 Loss:20.03 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.56 Step:764 CStep:794006\n",
            "Episode:925 Time:01:26:10 Reward:-21.00 Loss:25.48 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.06 Step:1004 CStep:795011\n",
            "Episode:926 Time:01:26:32 Reward:-21.00 Loss:20.75 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:21.96 Step:824 CStep:795836\n",
            "Episode:927 Time:01:26:56 Reward:-21.00 Loss:22.66 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.72 Step:884 CStep:796721\n",
            "Episode:928 Time:01:27:16 Reward:-21.00 Loss:19.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.56 Step:764 CStep:797486\n",
            "Episode:929 Time:01:27:37 Reward:-21.00 Loss:19.25 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.31 Step:764 CStep:798251\n",
            "Episode:930 Time:01:27:57 Reward:-21.00 Loss:19.56 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.59 Step:764 CStep:799016\n",
            "Episode:931 Time:01:28:20 Reward:-21.00 Loss:20.89 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.43 Step:824 CStep:799841\n",
            "Episode:932 Time:01:28:42 Reward:-21.00 Loss:21.20 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.51 Step:824 CStep:800666\n",
            "Episode:933 Time:01:29:03 Reward:-21.00 Loss:19.55 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.86 Step:764 CStep:801431\n",
            "Episode:934 Time:01:29:29 Reward:-21.00 Loss:23.53 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.75 Step:944 CStep:802376\n",
            "Episode:935 Time:01:29:51 Reward:-21.00 Loss:21.58 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.47 Step:824 CStep:803201\n",
            "Episode:936 Time:01:30:12 Reward:-21.00 Loss:18.30 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.64 Step:764 CStep:803966\n",
            "Episode:937 Time:01:30:33 Reward:-21.00 Loss:19.94 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.71 Step:764 CStep:804731\n",
            "Episode:938 Time:01:30:53 Reward:-21.00 Loss:19.50 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.66 Step:764 CStep:805496\n",
            "Episode:939 Time:01:31:14 Reward:-21.00 Loss:19.59 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.67 Step:764 CStep:806261\n",
            "Episode:940 Time:01:31:38 Reward:-21.00 Loss:22.24 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.13 Step:884 CStep:807146\n",
            "Episode:941 Time:01:32:00 Reward:-21.00 Loss:20.45 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.40 Step:824 CStep:807971\n",
            "Episode:942 Time:01:32:21 Reward:-21.00 Loss:19.34 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.80 Step:764 CStep:808736\n",
            "Episode:943 Time:01:32:42 Reward:-21.00 Loss:19.66 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.76 Step:764 CStep:809501\n",
            "Episode:944 Time:01:33:10 Reward:-21.00 Loss:27.36 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.86 Step:1032 CStep:810534\n",
            "Episode:945 Time:01:33:37 Reward:-21.00 Loss:25.35 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.16 Step:1004 CStep:811539\n",
            "Episode:946 Time:01:33:58 Reward:-21.00 Loss:19.77 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.76 Step:764 CStep:812304\n",
            "Episode:947 Time:01:34:19 Reward:-21.00 Loss:19.78 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.88 Step:764 CStep:813069\n",
            "Episode:948 Time:01:34:43 Reward:-21.00 Loss:22.10 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.01 Step:884 CStep:813954\n",
            "Episode:949 Time:01:35:10 Reward:-21.00 Loss:24.83 Last_100_Avg_Rew:-20.970 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.06 Step:1004 CStep:814959\n",
            "Episode:950 Time:01:35:34 Reward:-20.00 Loss:22.83 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.40 Step:902 CStep:815862\n",
            "Episode:951 Time:01:35:57 Reward:-21.00 Loss:21.30 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.35 Step:824 CStep:816687\n",
            "Episode:952 Time:01:36:17 Reward:-21.00 Loss:19.61 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.94 Step:764 CStep:817452\n",
            "Episode:953 Time:01:36:43 Reward:-21.00 Loss:24.59 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.62 Step:944 CStep:818397\n",
            "Episode:954 Time:01:37:04 Reward:-21.00 Loss:19.85 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.82 Step:764 CStep:819162\n",
            "Episode:955 Time:01:37:25 Reward:-21.00 Loss:19.65 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.83 Step:764 CStep:819927\n",
            "Episode:956 Time:01:37:55 Reward:-21.00 Loss:28.62 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:29.94 Step:1124 CStep:821052\n",
            "Episode:957 Time:01:38:15 Reward:-21.00 Loss:19.53 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.22 Step:764 CStep:821817\n",
            "Episode:958 Time:01:38:35 Reward:-21.00 Loss:19.74 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.52 Step:764 CStep:822582\n",
            "Episode:959 Time:01:38:58 Reward:-21.00 Loss:21.07 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.08 Step:824 CStep:823407\n",
            "Episode:960 Time:01:39:21 Reward:-21.00 Loss:22.43 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.67 Step:884 CStep:824292\n",
            "Episode:961 Time:01:39:42 Reward:-21.00 Loss:19.65 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:825057\n",
            "Episode:962 Time:01:40:02 Reward:-21.00 Loss:19.42 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.45 Step:764 CStep:825822\n",
            "Episode:963 Time:01:40:22 Reward:-21.00 Loss:19.97 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.41 Step:764 CStep:826587\n",
            "Episode:964 Time:01:40:44 Reward:-21.00 Loss:21.55 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.00 Step:824 CStep:827412\n",
            "Episode:965 Time:01:41:06 Reward:-21.00 Loss:21.32 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.00 Step:824 CStep:828237\n",
            "Episode:966 Time:01:41:29 Reward:-20.00 Loss:22.26 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.57 Step:842 CStep:829080\n",
            "Episode:967 Time:01:41:53 Reward:-21.00 Loss:22.44 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.11 Step:884 CStep:829965\n",
            "Episode:968 Time:01:42:17 Reward:-21.00 Loss:21.06 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.74 Step:884 CStep:830850\n",
            "Episode:969 Time:01:42:38 Reward:-21.00 Loss:19.51 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.64 Step:764 CStep:831615\n",
            "Episode:970 Time:01:43:05 Reward:-21.00 Loss:26.27 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:27.01 Step:1004 CStep:832620\n",
            "Episode:971 Time:01:43:28 Reward:-21.00 Loss:22.36 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.66 Step:884 CStep:833505\n",
            "Episode:972 Time:01:43:49 Reward:-21.00 Loss:19.70 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.57 Step:764 CStep:834270\n",
            "Episode:973 Time:01:44:14 Reward:-21.00 Loss:23.87 Last_100_Avg_Rew:-20.950 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.21 Step:944 CStep:835215\n",
            "Episode:974 Time:01:44:45 Reward:-20.00 Loss:29.98 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.19 Step:1161 CStep:836377\n",
            "Episode:975 Time:01:45:16 Reward:-20.00 Loss:29.36 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:31.11 Step:1159 CStep:837537\n",
            "Episode:976 Time:01:45:40 Reward:-21.00 Loss:22.38 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:23.86 Step:884 CStep:838422\n",
            "Episode:977 Time:01:46:01 Reward:-21.00 Loss:18.80 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.63 Step:764 CStep:839187\n",
            "Episode:978 Time:01:46:21 Reward:-21.00 Loss:19.21 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.52 Step:764 CStep:839952\n",
            "Episode:979 Time:01:46:44 Reward:-21.00 Loss:20.29 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.30 Step:824 CStep:840777\n",
            "Episode:980 Time:01:47:14 Reward:-21.00 Loss:28.84 Last_100_Avg_Rew:-20.930 Avg_Max_Q:0.000 Epsilon:0.05 Duration:30.63 Step:1124 CStep:841902\n",
            "Episode:981 Time:01:47:38 Reward:-21.00 Loss:21.60 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.05 Duration:24.13 Step:884 CStep:842787\n",
            "Episode:982 Time:01:48:01 Reward:-21.00 Loss:20.27 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.05 Duration:22.51 Step:824 CStep:843612\n",
            "Episode:983 Time:01:48:22 Reward:-21.00 Loss:18.70 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.89 Step:764 CStep:844377\n",
            "Episode:984 Time:01:48:48 Reward:-21.00 Loss:23.43 Last_100_Avg_Rew:-20.940 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.95 Step:944 CStep:845322\n",
            "Episode:985 Time:01:49:14 Reward:-21.00 Loss:23.21 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:25.95 Step:944 CStep:846267\n",
            "Episode:986 Time:01:49:35 Reward:-21.00 Loss:18.15 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.95 Step:764 CStep:847032\n",
            "Episode:987 Time:01:49:55 Reward:-21.00 Loss:19.32 Last_100_Avg_Rew:-20.960 Avg_Max_Q:0.000 Epsilon:0.05 Duration:20.73 Step:764 CStep:847797\n"
          ]
        }
      ],
      "source": [
        "environment = gym.make(ENVIRONMENT)  # Get env\n",
        "agent = Agent(environment)  # Create Agent\n",
        "\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\"))\n",
        "\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent.epsilon = param.get('epsilon')\n",
        "\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "\n",
        "else:\n",
        "    startEpisode = 1\n",
        "\n",
        "last_100_ep_reward = deque(maxlen=100)  # Last 100 episode rewards\n",
        "total_step = 1  # Cumulkative sum of all steps in episodes\n",
        "for episode in range(startEpisode, MAX_EPISODE):\n",
        "\n",
        "    startTime = time.time()  # Keep time\n",
        "    state = environment.reset()  # Reset env\n",
        "\n",
        "    state = agent.preProcess(state)  # Process image\n",
        "\n",
        "    # Stack state . Every state contains 4 time contionusly frames\n",
        "    # We stack frames like 4 channel image\n",
        "    state = np.stack((state, state, state, state))\n",
        "\n",
        "    total_max_q_val = 0  # Total max q vals\n",
        "    total_reward = 0  # Total reward for each episode\n",
        "    total_loss = 0  # Total loss for each episode\n",
        "    for step in range(MAX_STEP):\n",
        "\n",
        "        if RENDER_GAME_WINDOW:\n",
        "            environment.render()  # Show state visually\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.act(state)  # Act\n",
        "        next_state, reward, done, info = environment.step(action)  # Observe\n",
        "\n",
        "        next_state = agent.preProcess(next_state)  # Process image\n",
        "\n",
        "        # Stack state . Every state contains 4 time contionusly frames\n",
        "        # We stack frames like 4 channel image\n",
        "        next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "\n",
        "        # Store the transition in memory\n",
        "        agent.storeResults(state, action, reward, next_state, done)  # Store to mem\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state  # Update state\n",
        "\n",
        "        if TRAIN_MODEL:\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            loss, max_q_val = agent.train()  # Train with random BATCH_SIZE state taken from mem\n",
        "        else:\n",
        "            loss, max_q_val = [0, 0]\n",
        "\n",
        "        total_loss += loss\n",
        "        total_max_q_val += max_q_val\n",
        "        total_reward += reward\n",
        "        total_step += 1\n",
        "        if total_step % 1000 == 0:\n",
        "            agent.adaptiveEpsilon()  # Decrase epsilon\n",
        "\n",
        "        if done:  # Episode completed\n",
        "            currentTime = time.time()  # Keep current time\n",
        "            time_passed = currentTime - startTime  # Find episode duration\n",
        "            current_time_format = time.strftime(\"%H:%M:%S\", time.gmtime())  # Get current dateTime as HH:MM:SS\n",
        "            epsilonDict = {'epsilon': agent.epsilon}  # Create epsilon dict to save model as file\n",
        "\n",
        "            if SAVE_MODELS and episode % SAVE_MODEL_INTERVAL == 0:  # Save model as file\n",
        "                weightsPath = MODEL_PATH + str(episode) + '.pkl'\n",
        "                epsilonPath = MODEL_PATH + str(episode) + '.json'\n",
        "\n",
        "                torch.save(agent.online_model.state_dict(), weightsPath)\n",
        "                with open(epsilonPath, 'w') as outfile:\n",
        "                    json.dump(epsilonDict, outfile)\n",
        "\n",
        "            if TRAIN_MODEL:\n",
        "                agent.target_model.load_state_dict(agent.online_model.state_dict())  # Update target model\n",
        "\n",
        "            last_100_ep_reward.append(total_reward)\n",
        "            avg_max_q_val = total_max_q_val / step\n",
        "\n",
        "            outStr = \"Episode:{} Time:{} Reward:{:.2f} Loss:{:.2f} Last_100_Avg_Rew:{:.3f} Avg_Max_Q:{:.3f} Epsilon:{:.2f} Duration:{:.2f} Step:{} CStep:{}\".format(\n",
        "                episode, current_time_format, total_reward, total_loss, np.mean(last_100_ep_reward), avg_max_q_val, agent.epsilon, time_passed, step, total_step\n",
        "            )\n",
        "\n",
        "            print(outStr)\n",
        "\n",
        "            if SAVE_MODELS:\n",
        "                outputPath = MODEL_PATH + \"out\" + '.txt'  # Save outStr to file\n",
        "                with open(outputPath, 'a') as outfile:\n",
        "                    outfile.write(outStr+\"\\n\")\n",
        "\n",
        "            break\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}